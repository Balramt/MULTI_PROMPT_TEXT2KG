{"id": "ont_3_airport_test_1", "input text": "Abilene Regional Airport serves the city of Abilene in Jones County, Texas, United States.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Andrews County Airport is located in Texas (whose indigenes are called Texans), United States.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Andrews County Airport\", \"location\", \"Texas\"], [\"Texas\", \"demonym\", \"Texan\"], [\"Texas\", \"country\", \"United States\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Abilene Regional Airport serves the city of Abilene in Jones County, Texas, United States.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"cityServed\", \"Abilene\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Abilene Regional Airport serves the city of Abilene\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Abilene\", \"county\", \"Jones County\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"County\",\n      \"support\": \"Abilene Regional Airport serves the city of Abilene in Jones County\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"country\", \"United States\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Country\",\n      \"support\": \"Abilene Regional Airport serves the city of Abilene in Jones County, Texas, United States.\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Abilene Regional Airport", "cityServed", "Abilene"], "subject_type": "Airport", "object_type": "City", "support": "Abilene Regional Airport serves the city of Abilene", "confidence": 1.0}, {"triple": ["Abilene", "county", "Jones County"], "subject_type": "City", "object_type": "County", "support": "Abilene Regional Airport serves the city of Abilene in Jones County", "confidence": 1.0}, {"triple": ["Abilene Regional Airport", "country", "United States"], "subject_type": "Airport", "object_type": "Country", "support": "Abilene Regional Airport serves the city of Abilene in Jones County, Texas, United States.", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_2", "input text": "Abilene Regional Airport serves the city of Abilene which is in Texas, in the United States.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Texas is located in the United States, and its state capital is Austin. The Andrews County Airport is located in Texas.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Andrews County Airport\", \"location\", \"Texas\"], [\"Texas\", \"capital\", \"Austin, Texas\"], [\"Texas\", \"country\", \"United States\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Abilene Regional Airport serves the city of Abilene which is in Texas, in the United States.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"cityServed\", \"Abilene\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Abilene Regional Airport serves the city of Abilene\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Abilene\", \"location\", \"Texas\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"Place\",\n      \"support\": \"which is in Texas\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Abilene\", \"country\", \"United States\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"Country\",\n      \"support\": \"in the United States.\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Abilene Regional Airport", "cityServed", "Abilene"], "subject_type": "Airport", "object_type": "City", "support": "Abilene Regional Airport serves the city of Abilene", "confidence": 1.0}, {"triple": ["Abilene", "location", "Texas"], "subject_type": "City", "object_type": "Place", "support": "which is in Texas", "confidence": 1.0}, {"triple": ["Abilene", "country", "United States"], "subject_type": "City", "object_type": "Country", "support": "in the United States.", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_3", "input text": "Serving the city of Abilene in Texas, Abilene Regional Airport is 546 metres above sea level and has a runway length of 1,121 metres.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Located in Texas, Andrews County Airport is 973.0 above sea level and has a runway length of 8.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Andrews County Airport\", \"location\", \"Texas\"], [\"Andrews County Airport\", \"runwayLength\", \"8.0\"], [\"Andrews County Airport\", \"elevationAboveTheSeaLevel\", \"973.0\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Serving the city of Abilene in Texas, Abilene Regional Airport is 546 metres above sea level and has a runway length of 1,121 metres.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"cityServed\", \"Abilene\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Serving the city of Abilene\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"location\", \"Texas\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Country\",\n      \"support\": \"in Texas\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"elevationAboveTheSeaLevel\", \"546\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"546 metres above sea level\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"runwayLength\", \"1,121\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"has a runway length of 1,121 metres\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Abilene Regional Airport", "cityServed", "Abilene"], "subject_type": "Airport", "object_type": "City", "support": "Serving the city of Abilene", "confidence": 1.0}, {"triple": ["Abilene Regional Airport", "location", "Texas"], "subject_type": "Airport", "object_type": "Country", "support": "in Texas", "confidence": 1.0}, {"triple": ["Abilene Regional Airport", "elevationAboveTheSeaLevel", "546"], "subject_type": "Airport", "object_type": "number", "support": "546 metres above sea level", "confidence": 1.0}, {"triple": ["Abilene Regional Airport", "runwayLength", "1,121"], "subject_type": "Airport", "object_type": "number", "support": "has a runway length of 1,121 metres", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_4", "input text": "Abilene Regional Airport serves the city of Abilene in Texas. Its runway is 2194 feet and is 546 m above sea level.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Located in Texas, Andrews County Airport is 973.0 above sea level and has a runway length of 8.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Andrews County Airport\", \"location\", \"Texas\"], [\"Andrews County Airport\", \"runwayLength\", \"8.0\"], [\"Andrews County Airport\", \"elevationAboveTheSeaLevel\", \"973.0\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Abilene Regional Airport serves the city of Abilene in Texas. Its runway is 2194 feet and is 546 m above sea level.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"cityServed\", \"Abilene\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Abilene Regional Airport serves the city of Abilene\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"runwayLength\", \"2194 feet\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"Its runway is 2194 feet\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"elevationAboveTheSeaLevel\", \"546 m\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"and is 546 m above sea level\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"location\", \"Texas\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Abilene Regional Airport serves the city of Abilene in Texas\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Abilene Regional Airport", "cityServed", "Abilene"], "subject_type": "Airport", "object_type": "City", "support": "Abilene Regional Airport serves the city of Abilene", "confidence": 1.0}, {"triple": ["Abilene Regional Airport", "runwayLength", "2194 feet"], "subject_type": "Airport", "object_type": "number", "support": "Its runway is 2194 feet", "confidence": 1.0}, {"triple": ["Abilene Regional Airport", "elevationAboveTheSeaLevel", "546 m"], "subject_type": "Airport", "object_type": "number", "support": "and is 546 m above sea level", "confidence": 1.0}, {"triple": ["Abilene Regional Airport", "location", "Texas"], "subject_type": "Airport", "object_type": "Place", "support": "Abilene Regional Airport serves the city of Abilene in Texas", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_5", "input text": "Abilene Regional Airport, located 546 metres above sea level, serves the city of Abilene, Texas with a runway length of 2,195.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Located in Texas, Andrews County Airport is 973.0 above sea level and has a runway length of 8.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Andrews County Airport\", \"location\", \"Texas\"], [\"Andrews County Airport\", \"runwayLength\", \"8.0\"], [\"Andrews County Airport\", \"elevationAboveTheSeaLevel\", \"973.0\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Abilene Regional Airport, located 546 metres above sea level, serves the city of Abilene, Texas with a runway length of 2,195.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"elevationAboveTheSeaLevel\", \"546\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"located 546 metres above sea level\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"cityServed\", \"Abilene\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"serves the city of Abilene\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"runwayLength\", \"2195\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"with a runway length of 2,195\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"country\", \"United States\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Country\",\n      \"support\": \"implied as it is located in Texas, which is a state in the United States\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Abilene Regional Airport", "elevationAboveTheSeaLevel", "546"], "subject_type": "Airport", "object_type": "number", "support": "located 546 metres above sea level", "confidence": 1.0}, {"triple": ["Abilene Regional Airport", "cityServed", "Abilene"], "subject_type": "Airport", "object_type": "City", "support": "serves the city of Abilene", "confidence": 1.0}, {"triple": ["Abilene Regional Airport", "runwayLength", "2195"], "subject_type": "Airport", "object_type": "number", "support": "with a runway length of 2,195", "confidence": 1.0}, {"triple": ["Abilene Regional Airport", "country", "United States"], "subject_type": "Airport", "object_type": "Country", "support": "implied as it is located in Texas, which is a state in the United States", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_6", "input text": "Lake Placid, N.Y. is served by the Adirondack Regional Airport. This airport is 507 metres above sea level and serves the city of Saranac Lake, New York.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Ashgabat International Airport (located in Ashgabat) is elevated 211 metres above sea level and has a runway length of 3800.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Ashgabat International Airport\", \"location\", \"Ashgabat\"], [\"Ashgabat International Airport\", \"runwayLength\", \"3800.0\"], [\"Ashgabat International Airport\", \"elevationAboveTheSeaLevelInMetres\", \"211\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Lake Placid, N.Y. is served by the Adirondack Regional Airport. This airport is 507 metres above sea level and serves the city of Saranac Lake, New York.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Adirondack Regional Airport\", \"elevationAboveTheSeaLevelInMetres\", \"507\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"This airport is 507 metres above sea level\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Adirondack Regional Airport\", \"cityServed\", \"Saranac Lake, New York\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"this airport serves the city of Saranac Lake, New York\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Adirondack Regional Airport\", \"location\", \"Lake Placid, N.Y.\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Lake Placid, N.Y. is served by the Adirondack Regional Airport\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Adirondack Regional Airport", "elevationAboveTheSeaLevelInMetres", "507"], "subject_type": "Airport", "object_type": "number", "support": "This airport is 507 metres above sea level", "confidence": 1.0}, {"triple": ["Adirondack Regional Airport", "cityServed", "Saranac Lake, New York"], "subject_type": "Airport", "object_type": "City", "support": "this airport serves the city of Saranac Lake, New York", "confidence": 1.0}, {"triple": ["Adirondack Regional Airport", "location", "Lake Placid, N.Y."], "subject_type": "Airport", "object_type": "Place", "support": "Lake Placid, N.Y. is served by the Adirondack Regional Airport", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_7", "input text": "Curitiba is part of the State of Parana, in the south region of Brazil. The Afonso Pena International airport serves the city.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Antwerp International Airport serves the city of Antwerp which is in Belgium, where the capital is Brussels.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Antwerp International Airport\", \"cityServed\", \"Antwerp\"], [\"Antwerp\", \"country\", \"Belgium\"], [\"Belgium\", \"capital\", \"City of Brussels\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Curitiba is part of the State of Parana, in the south region of Brazil. The Afonso Pena International airport serves the city.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Curitiba\", \"city\", \"City\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"City\",\n      \"support\": \"Curitiba is part of the State of Parana\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Curitiba\", \"location\", \"Parana\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"Place\",\n      \"support\": \"Curitiba is part of the State of Parana\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Parana\", \"region\", \"South region of Brazil\"],\n      \"subject_type\": \"County\",\n      \"object_type\": \"Place\",\n      \"support\": \"Curitiba is part of the State of Parana, in the south region of Brazil\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Curitiba\", \"country\", \"Brazil\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"Country\",\n      \"support\": \"Curitiba is part of the State of Parana, in the south region of Brazil\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Afonso Pena International airport\", \"serves\", \"Curitiba\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"The Afonso Pena International airport serves the city.\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Curitiba", "city", "City"], "subject_type": "City", "object_type": "City", "support": "Curitiba is part of the State of Parana", "confidence": 1.0}, {"triple": ["Curitiba", "location", "Parana"], "subject_type": "City", "object_type": "Place", "support": "Curitiba is part of the State of Parana", "confidence": 1.0}, {"triple": ["Parana", "region", "South region of Brazil"], "subject_type": "County", "object_type": "Place", "support": "Curitiba is part of the State of Parana, in the south region of Brazil", "confidence": 1.0}, {"triple": ["Curitiba", "country", "Brazil"], "subject_type": "City", "object_type": "Country", "support": "Curitiba is part of the State of Parana, in the south region of Brazil", "confidence": 1.0}, {"triple": ["Afonso Pena International airport", "serves", "Curitiba"], "subject_type": "Airport", "object_type": "City", "support": "The Afonso Pena International airport serves the city.", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_8", "input text": "Afonso Pena International Airport serves Curitiba, which is part of the State of Parana and led by the Democratic Labour Party of Brazil.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Adolfo Suárez Madrid Barajas Airport is found in Alcobendas (Spain) where the leader party is the Peoples Party.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Alcobendas\", \"leaderParty\", \"People's Party (Spain)\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"location\", \"Alcobendas\"], [\"Alcobendas\", \"country\", \"Spain\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Afonso Pena International Airport serves Curitiba, which is part of the State of Parana and led by the Democratic Labour Party of Brazil.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Curitiba\", \"cityServed\", \"Afonso Pena International Airport\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"Airport\",\n      \"support\": \"Curitiba, which is part of the State of Parana\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Afonso Pena International Airport\", \"location\", \"State of Parana\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Curitiba, which is part of the State of Parana\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Afonso Pena International Airport\", \"operator\", \"Democratic Labour Party of Brazil\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Organisation\",\n      \"support\": \"led by the Democratic Labour Party of Brazil\",\n      \"confidence\": 0.8\n    },\n    {\n      \"triple\": [\"Afonso Pena International Airport\", \"country\", \"Brazil\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Country\",\n      \"support\": \"led by the Democratic Labour Party of Brazil\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Curitiba", "cityServed", "Afonso Pena International Airport"], "subject_type": "City", "object_type": "Airport", "support": "Curitiba, which is part of the State of Parana", "confidence": 1.0}, {"triple": ["Afonso Pena International Airport", "location", "State of Parana"], "subject_type": "Airport", "object_type": "Place", "support": "Curitiba, which is part of the State of Parana", "confidence": 1.0}, {"triple": ["Afonso Pena International Airport", "operator", "Democratic Labour Party of Brazil"], "subject_type": "Airport", "object_type": "Organisation", "support": "led by the Democratic Labour Party of Brazil", "confidence": 0.8}, {"triple": ["Afonso Pena International Airport", "country", "Brazil"], "subject_type": "Airport", "object_type": "Country", "support": "led by the Democratic Labour Party of Brazil", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_9", "input text": "Curitiba is part of the South Region, Brazil, is led by the Democratic Labour Party (Brazil) and is served by Afonso Pena International airport.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Adolfo Suárez Madrid Barajas Airport is found in Alcobendas which is part of the community of Madrid. The leader party at Alcobendas is the People's Party (Spain).\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Alcobendas\", \"isPartOf\", \"Community of Madrid\"], [\"Alcobendas\", \"leaderParty\", \"People's Party (Spain)\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"location\", \"Alcobendas\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Curitiba is part of the South Region, Brazil, is led by the Democratic Labour Party (Brazil) and is served by Afonso Pena International airport.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Curitiba\", \"city\", \"Curitiba\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"City\",\n      \"support\": \"Curitiba is part of the South Region, Brazil\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Curitiba\", \"location\", \"South Region, Brazil\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"Place\",\n      \"support\": \"Curitiba is part of the South Region, Brazil\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Curitiba\", \"country\", \"Brazil\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"Country\",\n      \"support\": \"Curitiba is part of the South Region, Brazil\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Curitiba\", \"leaderParty\", \"Democratic Labour Party (Brazil)\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"Party\",\n      \"support\": \"is led by the Democratic Labour Party (Brazil)\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Curitiba\", \"servedBy\", \"Afonso Pena International airport\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"Airport\",\n      \"support\": \"is served by Afonso Pena International airport\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Curitiba", "city", "Curitiba"], "subject_type": "City", "object_type": "City", "support": "Curitiba is part of the South Region, Brazil", "confidence": 1.0}, {"triple": ["Curitiba", "location", "South Region, Brazil"], "subject_type": "City", "object_type": "Place", "support": "Curitiba is part of the South Region, Brazil", "confidence": 1.0}, {"triple": ["Curitiba", "country", "Brazil"], "subject_type": "City", "object_type": "Country", "support": "Curitiba is part of the South Region, Brazil", "confidence": 1.0}, {"triple": ["Curitiba", "leaderParty", "Democratic Labour Party (Brazil)"], "subject_type": "City", "object_type": "Party", "support": "is led by the Democratic Labour Party (Brazil)", "confidence": 1.0}, {"triple": ["Curitiba", "servedBy", "Afonso Pena International airport"], "subject_type": "City", "object_type": "Airport", "support": "is served by Afonso Pena International airport", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_10", "input text": "Afonso Pena International airport is located in Sao Jose dos Pinhais and is operated by Infraero. It is 911 metres above sea level.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Adolfo Suarez Madrid-Barajas airport is located at Madrid, Paracuellos de Jarama, San Sebastián de los Reyes and Alcobendas. It is operated by ENAIRE and is 610 metres above sea level.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Adolfo Suárez Madrid–Barajas Airport\", \"operatingOrganisation\", \"ENAIRE\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"elevationAboveTheSeaLevel\", \"610.0\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"location\", \"Madrid, Paracuellos de Jarama, San Sebastián de los Reyes and Alcobendas\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Afonso Pena International airport is located in Sao Jose dos Pinhais and is operated by Infraero. It is 911 metres above sea level.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Afonso Pena International airport\", \"location\", \"Sao Jose dos Pinhais\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Afonso Pena International airport is located in Sao Jose dos Pinhais\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Afonso Pena International airport\", \"operator\", \"Infraero\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Organisation\",\n      \"support\": \"It is operated by Infraero\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Afonso Pena International airport\", \"elevationAboveTheSeaLevel\", \"911.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"It is 911 metres above sea level.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Afonso Pena International airport\", \"cityServed\", \"Sao Jose dos Pinhais\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Afonso Pena International airport is located in Sao Jose dos Pinhais\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Afonso Pena International airport", "location", "Sao Jose dos Pinhais"], "subject_type": "Airport", "object_type": "Place", "support": "Afonso Pena International airport is located in Sao Jose dos Pinhais", "confidence": 1.0}, {"triple": ["Afonso Pena International airport", "operator", "Infraero"], "subject_type": "Airport", "object_type": "Organisation", "support": "It is operated by Infraero", "confidence": 1.0}, {"triple": ["Afonso Pena International airport", "elevationAboveTheSeaLevel", "911.0"], "subject_type": "Airport", "object_type": "number", "support": "It is 911 metres above sea level.", "confidence": 1.0}, {"triple": ["Afonso Pena International airport", "cityServed", "Sao Jose dos Pinhais"], "subject_type": "Airport", "object_type": "City", "support": "Afonso Pena International airport is located in Sao Jose dos Pinhais", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_11", "input text": "Located at Sao Jose dos Pinhais, Afonso Pena International Airport has the runway name 11/29, and a runway length of 1800.0 metres.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Allama Iqbal International airport is located in Pakistan and has a runway named 18R/36L. The runway length is 2900.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Allama Iqbal International Airport\", \"location\", \"Pakistan\"], [\"Allama Iqbal International Airport\", \"runwayName\", \"18R/36L\"], [\"Allama Iqbal International Airport\", \"runwayLength\", \"2900.0\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Located at Sao Jose dos Pinhais, Afonso Pena International Airport has the runway name 11/29, and a runway length of 1800.0 metres.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Afonso Pena International Airport\", \"runwayName\", \"11/29\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"string\",\n      \"support\": \"Located at Sao Jose dos Pinhais, Afonso Pena International Airport has the runway name 11/29,\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Afonso Pena International Airport\", \"runwayLength\", \"1800.0 metres\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"and a runway length of 1800.0 metres.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Afonso Pena International Airport\", \"location\", \"Sao Jose dos Pinhais\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Located at Sao Jose dos Pinhais,\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Afonso Pena International Airport", "runwayName", "11/29"], "subject_type": "Airport", "object_type": "string", "support": "Located at Sao Jose dos Pinhais, Afonso Pena International Airport has the runway name 11/29,", "confidence": 1.0}, {"triple": ["Afonso Pena International Airport", "runwayLength", "1800.0 metres"], "subject_type": "Airport", "object_type": "number", "support": "and a runway length of 1800.0 metres.", "confidence": 1.0}, {"triple": ["Afonso Pena International Airport", "location", "Sao Jose dos Pinhais"], "subject_type": "Airport", "object_type": "Place", "support": "Located at Sao Jose dos Pinhais,", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_12", "input text": "Afonso Pena International Airport is located in Sao Jose dos Pinhais; its runway name is 15/33 and it is 1800 metres long.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The 18L/36R runway of the Allama Iqbal International airport is located in Punjab Pakistan and has a length of 33310.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Allama Iqbal International Airport\", \"runwayLength\", \"3310.0\"], [\"Allama Iqbal International Airport\", \"location\", \"Punjab, Pakistan\"], [\"Allama Iqbal International Airport\", \"runwayName\", \"18L/36R\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Afonso Pena International Airport is located in Sao Jose dos Pinhais; its runway name is 15/33 and it is 1800 metres long.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Afonso Pena International Airport\", \"runwayName\", \"15/33\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"string\",\n      \"support\": \"its runway name is 15/33\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Afonso Pena International Airport\", \"runwayLength\", \"1800\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"it is 1800 metres long\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Afonso Pena International Airport\", \"location\", \"Sao Jose dos Pinhais\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Afonso Pena International Airport is located in Sao Jose dos Pinhais\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Afonso Pena International Airport", "runwayName", "15/33"], "subject_type": "Airport", "object_type": "string", "support": "its runway name is 15/33", "confidence": 1.0}, {"triple": ["Afonso Pena International Airport", "runwayLength", "1800"], "subject_type": "Airport", "object_type": "number", "support": "it is 1800 metres long", "confidence": 1.0}, {"triple": ["Afonso Pena International Airport", "location", "Sao Jose dos Pinhais"], "subject_type": "Airport", "object_type": "Place", "support": "Afonso Pena International Airport is located in Sao Jose dos Pinhais", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_13", "input text": "The 11/29 runway in Afonso Pena International airport in Sao Jose dos Pinhais has a length of 2215.0.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Operated by Aarhus Lufthavn A/S, Aarhus Airport, has a runway length of 2702.0 metres and a runway named 10L/28R.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Aarhus Airport\", \"operatingOrganisation\", \"Aarhus Lufthavn A/S\"], [\"Aarhus Airport\", \"runwayName\", \"10L/28R\"], [\"Aarhus Airport\", \"runwayLength\", \"2702.0\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The 11/29 runway in Afonso Pena International airport in Sao Jose dos Pinhais has a length of 2215.0.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Afonso Pena International airport\", \"runwayLength\", \"2215.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"The 11/29 runway in Afonso Pena International airport has a length of 2215.0.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Afonso Pena International airport\", \"runwayName\", \"11/29\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"string\",\n      \"support\": \"The 11/29 runway in Afonso Pena International airport has a length of 2215.0.\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Afonso Pena International airport", "runwayLength", "2215.0"], "subject_type": "Airport", "object_type": "number", "support": "The 11/29 runway in Afonso Pena International airport has a length of 2215.0.", "confidence": 1.0}, {"triple": ["Afonso Pena International airport", "runwayName", "11/29"], "subject_type": "Airport", "object_type": "string", "support": "The 11/29 runway in Afonso Pena International airport has a length of 2215.0.", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_14", "input text": "Afonso Pena International Airport is located in São José dos Pinhais and has a runway length of 2215.0 which is named 15/33.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The 18L/36R runway of the Allama Iqbal International airport is located in Punjab Pakistan and has a length of 33310.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Allama Iqbal International Airport\", \"runwayLength\", \"3310.0\"], [\"Allama Iqbal International Airport\", \"location\", \"Punjab, Pakistan\"], [\"Allama Iqbal International Airport\", \"runwayName\", \"18L/36R\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Afonso Pena International Airport is located in São José dos Pinhais and has a runway length of 2215.0 which is named 15/33.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Afonso Pena International Airport\", \"location\", \"São José dos Pinhais\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Afonso Pena International Airport is located in São José dos Pinhais\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Afonso Pena International Airport\", \"runwayLength\", \"2215.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"which is named 15/33.\",\n      \"confidence\": 0.8\n    },\n    {\n      \"triple\": [\"Afonso Pena International Airport\", \"runwayName\", \"15/33\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"string\",\n      \"support\": \"which is named 15/33.\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Afonso Pena International Airport", "location", "São José dos Pinhais"], "subject_type": "Airport", "object_type": "City", "support": "Afonso Pena International Airport is located in São José dos Pinhais", "confidence": 1.0}, {"triple": ["Afonso Pena International Airport", "runwayLength", "2215.0"], "subject_type": "Airport", "object_type": "number", "support": "which is named 15/33.", "confidence": 0.8}, {"triple": ["Afonso Pena International Airport", "runwayName", "15/33"], "subject_type": "Airport", "object_type": "string", "support": "which is named 15/33.", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_15", "input text": "Agra Airport is in Uttar Pradesh, Awadh, and is located at 167.94 metres above sea level.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Ashgabat International Airport (located in Ashgabat) is elevated 211 metres above sea level and has a runway length of 3800.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Ashgabat International Airport\", \"location\", \"Ashgabat\"], [\"Ashgabat International Airport\", \"runwayLength\", \"3800.0\"], [\"Ashgabat International Airport\", \"elevationAboveTheSeaLevelInMetres\", \"211\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Agra Airport is in Uttar Pradesh, Awadh, and is located at 167.94 metres above sea level.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Agra Airport\", \"location\", \"Uttar Pradesh\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"County\",\n      \"support\": \"Agra Airport is in Uttar Pradesh,\"\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Agra Airport\", \"elevationAboveTheSeaLevelInMetres\", \"167.94\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"Agra Airport is located at 167.94 metres above sea level.\"\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": null}}
{"id": "ont_3_airport_test_16", "input text": "Agra Airport with an elevation of 167.94 meters above sea level is in Uttar Pradesh which is part of Bundelkhand.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Ashgabat is the location of Ashgabat International Airport which is elevated 211 metres above sea level and has a runway length of 900.0 metres.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Ashgabat International Airport\", \"location\", \"Ashgabat\"], [\"Ashgabat International Airport\", \"elevationAboveTheSeaLevelInMetres\", \"211\"], [\"Ashgabat International Airport\", \"runwayLength\", \"900.0\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Agra Airport with an elevation of 167.94 meters above sea level is in Uttar Pradesh which is part of Bundelkhand.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Agra Airport\", \"location\", \"Uttar Pradesh\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"County\",\n      \"support\": \"Agra Airport is in Uttar Pradesh\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Agra Airport\", \"elevationAboveTheSeaLevel\", \"167.94\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"Agra Airport with an elevation of 167.94 meters\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Uttar Pradesh\", \"partOf\", \"Bundelkhand\"],\n      \"subject_type\": \"County\",\n      \"object_type\": \"Place\",\n      \"support\": \"which is part of Bundelkhand\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Agra Airport", "location", "Uttar Pradesh"], "subject_type": "Airport", "object_type": "County", "support": "Agra Airport is in Uttar Pradesh", "confidence": 1.0}, {"triple": ["Agra Airport", "elevationAboveTheSeaLevel", "167.94"], "subject_type": "Airport", "object_type": "number", "support": "Agra Airport with an elevation of 167.94 meters", "confidence": 1.0}, {"triple": ["Uttar Pradesh", "partOf", "Bundelkhand"], "subject_type": "County", "object_type": "Place", "support": "which is part of Bundelkhand", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_17", "input text": "The Airports Authority of India is the operating organisation of Agra Airport which is located in India and has the location identifier VIAG.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Allama Iqbal International airport is located in Punjab Pakistan and is operated by Pakistan Civil Aviation Authority headquartered at Jinnah International Airport.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Allama Iqbal International Airport\", \"operatingOrganisation\", \"Pakistan Civil Aviation Authority\"], [\"Pakistan Civil Aviation Authority\", \"headquarter\", \"Jinnah International Airport\"], [\"Allama Iqbal International Airport\", \"location\", \"Punjab, Pakistan\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The Airports Authority of India is the operating organisation of Agra Airport which is located in India and has the location identifier VIAG.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"The Airports Authority of India\", \"operatingOrganisation\", \"Agra Airport\"],\n      \"subject_type\": \"Organisation\",\n      \"object_type\": \"Airport\",\n      \"support\": \"The Airports Authority of India is the operating organisation of Agra Airport\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Agra Airport\", \"location\", \"India\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Country\",\n      \"support\": \"Agra Airport is located in India\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Agra Airport\", \"locationIdentifier\", \"VIAG\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"string\",\n      \"support\": \"not explicitly mentioned but 'VIAG' is a common abbreviation for location identifiers\",\n      \"confidence\": 0.5\n    }\n  ]\n}", "json": {"triples": [{"triple": ["The Airports Authority of India", "operatingOrganisation", "Agra Airport"], "subject_type": "Organisation", "object_type": "Airport", "support": "The Airports Authority of India is the operating organisation of Agra Airport", "confidence": 1.0}, {"triple": ["Agra Airport", "location", "India"], "subject_type": "Airport", "object_type": "Country", "support": "Agra Airport is located in India", "confidence": 1.0}, {"triple": ["Agra Airport", "locationIdentifier", "VIAG"], "subject_type": "Airport", "object_type": "string", "support": "not explicitly mentioned but 'VIAG' is a common abbreviation for location identifiers", "confidence": 0.5}]}}}
{"id": "ont_3_airport_test_18", "input text": "Agra airport is located in India, where two of the leaders are T. S. Thakur and Narendra Modi.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Sardar Ayaz Sadiq is the leader of Pakistan which is where the City of Lahore is. this city is served by Allama Iqbal International airport.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Pakistan\", \"leader\", \"Sardar Ayaz Sadiq\"], [\"Lahore\", \"country\", \"Pakistan\"], [\"Allama Iqbal International Airport\", \"cityServed\", \"Lahore\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Agra airport is located in India, where two of the leaders are T. S. Thakur and Narendra Modi.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Agra airport\", \"location\", \"India\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Country\",\n      \"support\": \"Agra airport is located in India\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"T. S. Thakur\", \"leader\", \"Agra airport\"],\n      \"subject_type\": \"Person\",\n      \"object_type\": \"Airport\",\n      \"support\": \"two of the leaders are T. S. Thakur and Narendra Modi\",\n      \"confidence\": 0.8\n    },\n    {\n      \"triple\": [\"Narendra Modi\", \"leader\", \"Agra airport\"],\n      \"subject_type\": \"Person\",\n      \"object_type\": \"Airport\",\n      \"support\": \"two of the leaders are T. S. Thakur and Narendra Modi\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Agra airport", "location", "India"], "subject_type": "Airport", "object_type": "Country", "support": "Agra airport is located in India", "confidence": 1.0}, {"triple": ["T. S. Thakur", "leader", "Agra airport"], "subject_type": "Person", "object_type": "Airport", "support": "two of the leaders are T. S. Thakur and Narendra Modi", "confidence": 0.8}, {"triple": ["Narendra Modi", "leader", "Agra airport"], "subject_type": "Person", "object_type": "Airport", "support": "two of the leaders are T. S. Thakur and Narendra Modi", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_19", "input text": "The ICAO Location Identifier of Agra Airport in Uttar Pradesh is VIAG. The airport is operated by the AIrports Authority of India.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Appleton International airport is located in Greenville, Wisconsin which is part of Grand Chute, Wisconsin, in the United States.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Appleton International Airport\", \"location\", \"Greenville, Wisconsin\"], [\"Greenville\", \"isPartOf\", \"Wisconsin, Grand Chute, Wisconsin\"], [\"Greenville\", \"country\", \"Wisconsin, United States\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The ICAO Location Identifier of Agra Airport in Uttar Pradesh is VIAG. The airport is operated by the AIrports Authority of India.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Agra Airport\", \"icaoLocationIdentifier\", \"VIAG\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"string\",\n      \"support\": \"The ICAO Location Identifier of Agra Airport is VIAG.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Agra Airport\", \"operator\", \"Airports Authority of India\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Organisation\",\n      \"support\": \"The airport is operated by the Airports Authority of India.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Agra Airport\", \"location\", \"Uttar Pradesh\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Agra Airport is in Uttar Pradesh\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Agra Airport", "icaoLocationIdentifier", "VIAG"], "subject_type": "Airport", "object_type": "string", "support": "The ICAO Location Identifier of Agra Airport is VIAG.", "confidence": 1.0}, {"triple": ["Agra Airport", "operator", "Airports Authority of India"], "subject_type": "Airport", "object_type": "Organisation", "support": "The airport is operated by the Airports Authority of India.", "confidence": 1.0}, {"triple": ["Agra Airport", "location", "Uttar Pradesh"], "subject_type": "Airport", "object_type": "Place", "support": "Agra Airport is in Uttar Pradesh", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_20", "input text": "Agra Airport is located in Uttar Pradesh which is part of Awadh and Bundelkhand.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Appleton International Airport is located in Appleton Wisconsin which is a part of Kimberly and Grand Chute.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Appleton\", \"isPartOf\", \"Wisconsin, Kimberly, Wisconsin\"], [\"Appleton International Airport\", \"cityServed\", \"Appleton, Wisconsin\"], [\"Appleton\", \"isPartOf\", \"Wisconsin, Grand Chute, Wisconsin\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Agra Airport is located in Uttar Pradesh which is part of Awadh and Bundelkhand.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Agra Airport\", \"city\", \"Uttar Pradesh\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Agra Airport is located in Uttar Pradesh\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Uttar Pradesh\", \"isPartOf\", \"Awadh\"],\n      \"subject_type\": \"County\",\n      \"object_type\": \"Place\",\n      \"support\": \"Uttar Pradesh which is part of Awadh\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Uttar Pradesh\", \"isPartOf\", \"Bundelkhand\"],\n      \"subject_type\": \"County\",\n      \"object_type\": \"Place\",\n      \"support\": \"Uttar Pradesh which is part of Bundelkhand\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Agra Airport\", \"country\", \"India\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Country\",\n      \"support\": \"Agra Airport is located in Uttar Pradesh\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Agra Airport", "city", "Uttar Pradesh"], "subject_type": "Airport", "object_type": "City", "support": "Agra Airport is located in Uttar Pradesh", "confidence": 1.0}, {"triple": ["Uttar Pradesh", "isPartOf", "Awadh"], "subject_type": "County", "object_type": "Place", "support": "Uttar Pradesh which is part of Awadh", "confidence": 1.0}, {"triple": ["Uttar Pradesh", "isPartOf", "Bundelkhand"], "subject_type": "County", "object_type": "Place", "support": "Uttar Pradesh which is part of Bundelkhand", "confidence": 1.0}, {"triple": ["Agra Airport", "country", "India"], "subject_type": "Airport", "object_type": "Country", "support": "Agra Airport is located in Uttar Pradesh", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_21", "input text": "Awadh is part of Uttar Pradesh which is where Agra Airport is and where Ram Naik is the leader.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Allama Iqbal International Airport serves the city of Lahore which is in Pakistan where Nawaz Sharif is the leader.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Lahore\", \"country\", \"Pakistan\"], [\"Allama Iqbal International Airport\", \"cityServed\", \"Lahore\"], [\"Pakistan\", \"leader\", \"Nawaz Sharif\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Awadh is part of Uttar Pradesh which is where Agra Airport is and where Ram Naik is the leader.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Awadh\", \"isPartOf\", \"Uttar Pradesh\"],\n      \"subject_type\": \"Place\",\n      \"object_type\": \"County\",\n      \"support\": \"Awadh is part of Uttar Pradesh\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Uttar Pradesh\", \"city\", \"Agra\"],\n      \"subject_type\": \"County\",\n      \"object_type\": \"City\",\n      \"support\": \"where Agra Airport is\",\n      \"confidence\": 0.8\n    },\n    {\n      \"triple\": [\"Agra Airport\", \"location\", \"Uttar Pradesh\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"where Agra Airport is\",\n      \"confidence\": 0.8\n    },\n    {\n      \"triple\": [\"Agra Airport\", \"leader\", \"Ram Naik\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Person\",\n      \"support\": \"where Ram Naik is the leader.\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Awadh", "isPartOf", "Uttar Pradesh"], "subject_type": "Place", "object_type": "County", "support": "Awadh is part of Uttar Pradesh", "confidence": 1.0}, {"triple": ["Uttar Pradesh", "city", "Agra"], "subject_type": "County", "object_type": "City", "support": "where Agra Airport is", "confidence": 0.8}, {"triple": ["Agra Airport", "location", "Uttar Pradesh"], "subject_type": "Airport", "object_type": "Place", "support": "where Agra Airport is", "confidence": 0.8}, {"triple": ["Agra Airport", "leader", "Ram Naik"], "subject_type": "Airport", "object_type": "Person", "support": "where Ram Naik is the leader.", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_22", "input text": "Agra Airport is in Uttar Pradesh, Bundelkhand, whose leader is Ram Naik.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Allama Iqbal International Airport serves the city of Lahore which is in Pakistan where Nawaz Sharif is the leader.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Lahore\", \"country\", \"Pakistan\"], [\"Allama Iqbal International Airport\", \"cityServed\", \"Lahore\"], [\"Pakistan\", \"leader\", \"Nawaz Sharif\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Agra Airport is in Uttar Pradesh, Bundelkhand, whose leader is Ram Naik.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Agra Airport\", \"city\", \"Uttar Pradesh\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Agra Airport is in Uttar Pradesh\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Uttar Pradesh\", \"leader\", \"Ram Naik\"],\n      \"subject_type\": \"County\",\n      \"object_type\": \"Person\",\n      \"support\": \"whose leader is Ram Naik\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Agra Airport", "city", "Uttar Pradesh"], "subject_type": "Airport", "object_type": "City", "support": "Agra Airport is in Uttar Pradesh", "confidence": 1.0}, {"triple": ["Uttar Pradesh", "leader", "Ram Naik"], "subject_type": "County", "object_type": "Person", "support": "whose leader is Ram Naik", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_23", "input text": "The ICAO Location Identifier of Agra Airport is VIAG and the airport in Agra is operated by the Indian Air Force.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Bedford Aerodrome's International Civil Aviation Organization (ICAO) identifier is EGBF and has a runway called 08/26.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Bedford Aerodrome\", \"icaoLocationIdentifier\", \"EGBF\"], [\"Bedford Aerodrome\", \"runwayName\", \"08/26\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The ICAO Location Identifier of Agra Airport is VIAG and the airport in Agra is operated by the Indian Air Force.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Agra Airport\", \"icaoLocationIdentifier\", \"VIAG\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"string\",\n      \"support\": \"The ICAO Location Identifier of Agra Airport is VIAG\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Agra Airport\", \"operator\", \"Indian Air Force\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Organisation\",\n      \"support\": \"the airport in Agra is operated by the Indian Air Force\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Agra Airport", "icaoLocationIdentifier", "VIAG"], "subject_type": "Airport", "object_type": "string", "support": "The ICAO Location Identifier of Agra Airport is VIAG", "confidence": 1.0}, {"triple": ["Agra Airport", "operator", "Indian Air Force"], "subject_type": "Airport", "object_type": "Organisation", "support": "the airport in Agra is operated by the Indian Air Force", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_24", "input text": "Alderney is served by Alderney Airport. This airport's 1st runway is made from Poaceae and it has a runway length of 497.0.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Adolfo Suárez Madrid–Barajas Airport is in Alcobendas and is operated by ENAIRE in which is in Madrid. The runway length of Adolfo Suárez Madrid–Barajas Airport is 4,349 and is named 14R/32L, Adolfo Suárez Madrid-Barajas Airport also has an elevation of 610.0 metres above sea level and a runway length of 4,349.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Adolfo Suárez Madrid–Barajas Airport\", \"operatingOrganisation\", \"ENAIRE\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"location\", \"Alcobendas\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayLength\", \"4349.0\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayName\", \"14R/32L\"], [\"ENAIRE\", \"city\", \"Madrid\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"elevationAboveTheSeaLevel\", \"610.0\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Alderney is served by Alderney Airport. This airport's 1st runway is made from Poaceae and it has a runway length of 497.0.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alderney Airport\", \"runwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"This airport's 1st runway is made from Poaceae\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alderney Airport\", \"runwayLength\", \"497.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"it has a runway length of 497.0\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alderney Airport", "runwaySurfaceType", "Poaceae"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "This airport's 1st runway is made from Poaceae", "confidence": 1.0}, {"triple": ["Alderney Airport", "runwayLength", "497.0"], "subject_type": "Airport", "object_type": "number", "support": "it has a runway length of 497.0", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_25", "input text": "The 1st runway at Alderney Airport is made from Poaceae which belongs to the order of Commelinids and is in the class Monocotyledon.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The Bedford Aerodrome runway name is 08/26, it is 1095 long and the surface is made of concrete, it is also 83.2104 meters above sea level. The ICAO location identifier for the aerodrome is EGBF.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Bedford Aerodrome\", \"runwayLength\", \"1095.0\"], [\"Bedford Aerodrome\", \"icaoLocationIdentifier\", \"EGBF\"], [\"Bedford Aerodrome\", \"elevationAboveTheSeaLevel\", \"83.2104\"], [\"Bedford Aerodrome\", \"runwayName\", \"08/26\"], [\"Bedford Aerodrome\", \"runwaySurfaceType\", \"Concrete\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The 1st runway at Alderney Airport is made from Poaceae which belongs to the order of Commelinids and is in the class Monocotyledon.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alderney Airport\", \"1stRunwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The 1st runway at Alderney Airport is made from Poaceae\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Poaceae\", \"belongsTo\", \"Commelinids\"],\n      \"subject_type\": \"RunwaySurfaceType\",\n      \"object_type\": \"Class\",\n      \"support\": \"which belongs to the order of Commelinids\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Poaceae\", \"isPartOf\", \"Monocotyledon\"],\n      \"subject_type\": \"RunwaySurfaceType\",\n      \"object_type\": \"Class\",\n      \"support\": \"and is in the class Monocotyledon\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alderney Airport", "1stRunwaySurfaceType", "Poaceae"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "The 1st runway at Alderney Airport is made from Poaceae", "confidence": 1.0}, {"triple": ["Poaceae", "belongsTo", "Commelinids"], "subject_type": "RunwaySurfaceType", "object_type": "Class", "support": "which belongs to the order of Commelinids", "confidence": 1.0}, {"triple": ["Poaceae", "isPartOf", "Monocotyledon"], "subject_type": "RunwaySurfaceType", "object_type": "Class", "support": "and is in the class Monocotyledon", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_26", "input text": "The 1st runway at Alderney Airport is made from Poaceae, a Monocotyledon classed member of the order of Poales.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The Bedford Aerodrome runway name is 08/26, it is 1095 long and the surface is made of concrete, it is also 83.2104 meters above sea level. The ICAO location identifier for the aerodrome is EGBF.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Bedford Aerodrome\", \"runwayLength\", \"1095.0\"], [\"Bedford Aerodrome\", \"icaoLocationIdentifier\", \"EGBF\"], [\"Bedford Aerodrome\", \"elevationAboveTheSeaLevel\", \"83.2104\"], [\"Bedford Aerodrome\", \"runwayName\", \"08/26\"], [\"Bedford Aerodrome\", \"runwaySurfaceType\", \"Concrete\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The 1st runway at Alderney Airport is made from Poaceae, a Monocotyledon classed member of the order of Poales.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alderney Airport\", \"runwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The 1st runway at Alderney Airport is made from Poaceae\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Poaceae\", \"class\", \"Monocotyledon\"],\n      \"subject_type\": \"RunwaySurfaceType\",\n      \"object_type\": \"Class\",\n      \"support\": \"Poaceae, a Monocotyledon\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Poaceae\", \"order\", \"Poales\"],\n      \"subject_type\": \"RunwaySurfaceType\",\n      \"object_type\": \"Class\",\n      \"support\": \"Poaceae, a Monocotyledon classed member of the order of Poales\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alderney Airport", "runwaySurfaceType", "Poaceae"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "The 1st runway at Alderney Airport is made from Poaceae", "confidence": 1.0}, {"triple": ["Poaceae", "class", "Monocotyledon"], "subject_type": "RunwaySurfaceType", "object_type": "Class", "support": "Poaceae, a Monocotyledon", "confidence": 1.0}, {"triple": ["Poaceae", "order", "Poales"], "subject_type": "RunwaySurfaceType", "object_type": "Class", "support": "Poaceae, a Monocotyledon classed member of the order of Poales", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_27", "input text": "The surface of the 1st runway at Alderney airport is made from Poaceae of the orders Poales and Commelinids.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The Bedford Aerodrome runway name is 08/26, it is 1095 long and the surface is made of concrete, it is also 83.2104 meters above sea level. The ICAO location identifier for the aerodrome is EGBF.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Bedford Aerodrome\", \"runwayLength\", \"1095.0\"], [\"Bedford Aerodrome\", \"icaoLocationIdentifier\", \"EGBF\"], [\"Bedford Aerodrome\", \"elevationAboveTheSeaLevel\", \"83.2104\"], [\"Bedford Aerodrome\", \"runwayName\", \"08/26\"], [\"Bedford Aerodrome\", \"runwaySurfaceType\", \"Concrete\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The surface of the 1st runway at Alderney airport is made from Poaceae of the orders Poales and Commelinids.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alderney airport\", \"1stRunwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The surface of the 1st runway at Alderney airport is made from Poaceae\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alderney airport\", \"1stRunwaySurfaceTypeOrder\", \"Poales\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Division\",\n      \"support\": \"of the orders Poales and Commelinids\",\n      \"confidence\": 0.8\n    },\n    {\n      \"triple\": [\"Alderney airport\", \"1stRunwaySurfaceTypeOrder\", \"Commelinids\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Division\",\n      \"support\": \"of the orders Poales and Commelinids\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alderney airport", "1stRunwaySurfaceType", "Poaceae"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "The surface of the 1st runway at Alderney airport is made from Poaceae", "confidence": 1.0}, {"triple": ["Alderney airport", "1stRunwaySurfaceTypeOrder", "Poales"], "subject_type": "Airport", "object_type": "Division", "support": "of the orders Poales and Commelinids", "confidence": 0.8}, {"triple": ["Alderney airport", "1stRunwaySurfaceTypeOrder", "Commelinids"], "subject_type": "Airport", "object_type": "Division", "support": "of the orders Poales and Commelinids", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_28", "input text": "The city of Alderney is served by Alderney Airport. This airport has a runway length of 497.0 metres and its 1st runway has an asphalt surface.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Amsterdam Airport Schiphol serves the city of Amsterdam, it has a runway length of 3453.0 and is -3.3528 metres above sea level.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Amsterdam Airport Schiphol\", \"cityServed\", \"Amsterdam\"], [\"Amsterdam Airport Schiphol\", \"runwayLength\", \"3453.0\"], [\"Amsterdam Airport Schiphol\", \"elevationAboveTheSeaLevel\", \"-3.3528\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The city of Alderney is served by Alderney Airport. This airport has a runway length of 497.0 metres and its 1st runway has an asphalt surface.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alderney Airport\", \"cityServed\", \"Alderney\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"The city of Alderney is served by Alderney Airport.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alderney Airport\", \"runwayLength\", \"497.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"This airport has a runway length of 497.0 metres\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alderney Airport\", \"1stRunwaySurfaceType\", \"asphalt\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"its 1st runway has an asphalt surface.\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alderney Airport", "cityServed", "Alderney"], "subject_type": "Airport", "object_type": "City", "support": "The city of Alderney is served by Alderney Airport.", "confidence": 1.0}, {"triple": ["Alderney Airport", "runwayLength", "497.0"], "subject_type": "Airport", "object_type": "number", "support": "This airport has a runway length of 497.0 metres", "confidence": 1.0}, {"triple": ["Alderney Airport", "1stRunwaySurfaceType", "asphalt"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "its 1st runway has an asphalt surface.", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_29", "input text": "Alderney is served by Alderney Airport which has a runway length of 733.0 metres. Additionally, its 1st runway has an asphalt surface.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The Port Authority of New York and New Jersey operate Atlantic City International Airport. This airport has a runway length of 3048 metres and a runway named \\\"13/31\\\".\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Atlantic City International Airport\", \"runwayLength\", \"3048.0\"], [\"Atlantic City International Airport\", \"operatingOrganisation\", \"Port Authority of New York and New Jersey\"], [\"Atlantic City International Airport\", \"runwayName\", \"13/31\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Alderney is served by Alderney Airport which has a runway length of 733.0 metres. Additionally, its 1st runway has an asphalt surface.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alderney Airport\", \"runwayLength\", \"733.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"Alderney is served by Alderney Airport which has a runway length of 733.0 metres.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alderney Airport\", \"runwaySurfaceType\", \"asphalt\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"Additionally, its 1st runway has an asphalt surface.\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alderney Airport", "runwayLength", "733.0"], "subject_type": "Airport", "object_type": "number", "support": "Alderney is served by Alderney Airport which has a runway length of 733.0 metres.", "confidence": 1.0}, {"triple": ["Alderney Airport", "runwaySurfaceType", "asphalt"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "Additionally, its 1st runway has an asphalt surface.", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_30", "input text": "The 1st runway at Alderney Airport is made from Asphalt and has a length of 877.0.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Atlantic City International Airport is in Egg Harbor Township, New Jersey, the USA. Its runway length is 1873.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Atlantic City International Airport\", \"runwayLength\", \"1873.0\"], [\"Atlantic City International Airport\", \"location\", \"Egg Harbor Township, New Jersey\"], [\"Egg Harbor Township\", \"country\", \"New Jersey, United States\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The 1st runway at Alderney Airport is made from Asphalt and has a length of 877.0.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alderney Airport\", \"runwaySurfaceType\", \"Asphalt\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The 1st runway at Alderney Airport is made from Asphalt\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alderney Airport\", \"runwayLength\", \"877.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"has a length of 877.0\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"1st runway at Alderney Airport\", \"runwaySurfaceType\", \"Asphalt\"],\n      \"subject_type\": \"Runway\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The 1st runway at Alderney Airport is made from Asphalt\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alderney Airport", "runwaySurfaceType", "Asphalt"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "The 1st runway at Alderney Airport is made from Asphalt", "confidence": 1.0}, {"triple": ["Alderney Airport", "runwayLength", "877.0"], "subject_type": "Airport", "object_type": "number", "support": "has a length of 877.0", "confidence": 1.0}, {"triple": ["1st runway at Alderney Airport", "runwaySurfaceType", "Asphalt"], "subject_type": "Runway", "object_type": "RunwaySurfaceType", "support": "The 1st runway at Alderney Airport is made from Asphalt", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_31", "input text": "Alpena County Regional Airport, located in Maple Ridge Township, Michigan has a runway length of 1533.0 and has an elevation of 210 meters.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Appleton International Airport located in Greenville, Wisconsin, has an elevation of 280 meters above sea level as well as a runway length of 2,439.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Appleton International Airport\", \"location\", \"Greenville, Wisconsin\"], [\"Appleton International Airport\", \"runwayLength\", \"2439.0\"], [\"Appleton International Airport\", \"elevationAboveTheSeaLevel\", \"280\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Alpena County Regional Airport, located in Maple Ridge Township, Michigan has a runway length of 1533.0 and has an elevation of 210 meters.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"location\", \"Maple Ridge Township\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Alpena County Regional Airport, located in Maple Ridge Township\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"runwayLength\", \"1533.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"has a runway length of 1533.0\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"elevationAboveTheSeaLevel\", \"210\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"has an elevation of 210 meters\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alpena County Regional Airport", "location", "Maple Ridge Township"], "subject_type": "Airport", "object_type": "Place", "support": "Alpena County Regional Airport, located in Maple Ridge Township", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "runwayLength", "1533.0"], "subject_type": "Airport", "object_type": "number", "support": "has a runway length of 1533.0", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "elevationAboveTheSeaLevel", "210"], "subject_type": "Airport", "object_type": "number", "support": "has an elevation of 210 meters", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_32", "input text": "The runway length of Alpena County Regional Airport is 1,533 and it is located at Maple Ridge Township, Alpena County, Michigan, United States.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The 18L/36R runway in Allama Iqbal International airport in Pakistan, has a length of 3310.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Allama Iqbal International Airport\", \"location\", \"Pakistan\"], [\"Allama Iqbal International Airport\", \"runwayLength\", \"3310.0\"], [\"Allama Iqbal International Airport\", \"runwayName\", \"18L/36R\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The runway length of Alpena County Regional Airport is 1,533 and it is located at Maple Ridge Township, Alpena County, Michigan, United States.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"location\", \"Maple Ridge Township\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"it is located at Maple Ridge Township\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"location\", \"Alpena County\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"County\",\n      \"support\": \"Maple Ridge Township, Alpena County\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"location\", \"Michigan\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"County\",\n      \"support\": \"Alpena County, Michigan\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"location\", \"United States\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Country\",\n      \"support\": \"Alpena County, Michigan, United States\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"runwayLength\", \"1533\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"The runway length of Alpena County Regional Airport is 1,533\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alpena County Regional Airport", "location", "Maple Ridge Township"], "subject_type": "Airport", "object_type": "Place", "support": "it is located at Maple Ridge Township", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "location", "Alpena County"], "subject_type": "Airport", "object_type": "County", "support": "Maple Ridge Township, Alpena County", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "location", "Michigan"], "subject_type": "Airport", "object_type": "County", "support": "Alpena County, Michigan", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "location", "United States"], "subject_type": "Airport", "object_type": "Country", "support": "Alpena County, Michigan, United States", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "runwayLength", "1533"], "subject_type": "Airport", "object_type": "number", "support": "The runway length of Alpena County Regional Airport is 1,533", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_33", "input text": "Alpena County Regional Airport has a runway length is 2744.0 metres and is located in Maple Ridge Township, Alpena County, Michigan, in the United States.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Appleton International Airport is 280 metres above sea level and has a runway length of 2439.0. It is operated from Outagamie County, Wisconsin.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Appleton International Airport\", \"runwayLength\", \"2439.0\"], [\"Appleton International Airport\", \"elevationAboveTheSeaLevel\", \"280\"], [\"Appleton International Airport\", \"operatingOrganisation\", \"Outagamie County, Wisconsin\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Alpena County Regional Airport has a runway length is 2744.0 metres and is located in Maple Ridge Township, Alpena County, Michigan, in the United States.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"runwayLength\", \"2744.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"has a runway length is 2744.0 metres\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"location\", \"Maple Ridge Township, Alpena County, Michigan, in the United States\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"is located in Maple Ridge Township, Alpena County, Michigan, in the United States\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"county\", \"Alpena County\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"County\",\n      \"support\": \"in Alpena County\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alpena County Regional Airport", "runwayLength", "2744.0"], "subject_type": "Airport", "object_type": "number", "support": "has a runway length is 2744.0 metres", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "location", "Maple Ridge Township, Alpena County, Michigan, in the United States"], "subject_type": "Airport", "object_type": "Place", "support": "is located in Maple Ridge Township, Alpena County, Michigan, in the United States", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "county", "Alpena County"], "subject_type": "Airport", "object_type": "County", "support": "in Alpena County", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_34", "input text": "Found in Wilson Township, Alpena County, Michigan, is Alpena County Regional Airport. This airport is 210 metres above sea level and has a runway length of 2744.0 metres.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Appleton International Airport is 280 metres above sea level and has a runway length of 2439.0. It is operated from Outagamie County, Wisconsin.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Appleton International Airport\", \"runwayLength\", \"2439.0\"], [\"Appleton International Airport\", \"elevationAboveTheSeaLevel\", \"280\"], [\"Appleton International Airport\", \"operatingOrganisation\", \"Outagamie County, Wisconsin\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Found in Wilson Township, Alpena County, Michigan, is Alpena County Regional Airport. This airport is 210 metres above sea level and has a runway length of 2744.0 metres.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"elevationAboveTheSeaLevel\", \"210\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"This airport is 210 metres above sea level\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"runwayLength\", \"2744.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"has a runway length of 2744.0 metres\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"location\", \"Wilson Township, Alpena County, Michigan\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Found in Wilson Township, Alpena County, Michigan\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"county\", \"Alpena County\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"County\",\n      \"support\": \"Alpena County, Michigan\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"cityServed\", \"Alpena County\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Alpena County, Michigan\",\n      \"confidence\": 0.75\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alpena County Regional Airport", "elevationAboveTheSeaLevel", "210"], "subject_type": "Airport", "object_type": "number", "support": "This airport is 210 metres above sea level", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "runwayLength", "2744.0"], "subject_type": "Airport", "object_type": "number", "support": "has a runway length of 2744.0 metres", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "location", "Wilson Township, Alpena County, Michigan"], "subject_type": "Airport", "object_type": "Place", "support": "Found in Wilson Township, Alpena County, Michigan", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "county", "Alpena County"], "subject_type": "Airport", "object_type": "County", "support": "Alpena County, Michigan", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "cityServed", "Alpena County"], "subject_type": "Airport", "object_type": "City", "support": "Alpena County, Michigan", "confidence": 0.75}]}}}
{"id": "ont_3_airport_test_35", "input text": "With an elevation of 210 metres above sea level, Alpena County Regional Airport is located in the Wilson Township, in Alpena County, Michigan, in the U.S.A.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Appleton International Airport is elevated 280 metres above sea level and has a runway length of 1982.0. It is operated by an organisation in Outagamie County, Wisconsin.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Appleton International Airport\", \"runwayLength\", \"1982.0\"], [\"Appleton International Airport\", \"elevationAboveTheSeaLevel\", \"280\"], [\"Appleton International Airport\", \"operatingOrganisation\", \"Outagamie County, Wisconsin\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"With an elevation of 210 metres above sea level, Alpena County Regional Airport is located in the Wilson Township, in Alpena County, Michigan, in the U.S.A.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"elevationAboveTheSeaLevel\", \"210\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"With an elevation of 210 metres above sea level\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"location\", \"Wilson Township\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"located in the Wilson Township\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"county\", \"Alpena County\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"County\",\n      \"support\": \"in Alpena County\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"country\", \"USA\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Country\",\n      \"support\": \"in the U.S.A.\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alpena County Regional Airport", "elevationAboveTheSeaLevel", "210"], "subject_type": "Airport", "object_type": "number", "support": "With an elevation of 210 metres above sea level", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "location", "Wilson Township"], "subject_type": "Airport", "object_type": "Place", "support": "located in the Wilson Township", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "county", "Alpena County"], "subject_type": "Airport", "object_type": "County", "support": "in Alpena County", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "country", "USA"], "subject_type": "Airport", "object_type": "Country", "support": "in the U.S.A.", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_36", "input text": "Alpena County Regional Airport is located in Wilson Township, Alpena County, Michigan in the United States. It has a runway length of 1533.0.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The 18L/36R runway in Allama Iqbal International airport in Pakistan, has a length of 3310.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Allama Iqbal International Airport\", \"location\", \"Pakistan\"], [\"Allama Iqbal International Airport\", \"runwayLength\", \"3310.0\"], [\"Allama Iqbal International Airport\", \"runwayName\", \"18L/36R\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Alpena County Regional Airport is located in Wilson Township, Alpena County, Michigan in the United States. It has a runway length of 1533.0.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"location\", \"Wilson Township\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Alpena County Regional Airport is located in Wilson Township\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"location\", \"Alpena County\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Alpena County Regional Airport is located in Alpena County\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"location\", \"Michigan\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Alpena County Regional Airport is located in the United States. It has a runway length of 1533.0.\",\n      \"confidence\": 0.8\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"runwayLength\", \"1533.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"It has a runway length of 1533.0.\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alpena County Regional Airport", "location", "Wilson Township"], "subject_type": "Airport", "object_type": "Place", "support": "Alpena County Regional Airport is located in Wilson Township", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "location", "Alpena County"], "subject_type": "Airport", "object_type": "Place", "support": "Alpena County Regional Airport is located in Alpena County", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "location", "Michigan"], "subject_type": "Airport", "object_type": "Place", "support": "Alpena County Regional Airport is located in the United States. It has a runway length of 1533.0.", "confidence": 0.8}, {"triple": ["Alpena County Regional Airport", "runwayLength", "1533.0"], "subject_type": "Airport", "object_type": "number", "support": "It has a runway length of 1533.0.", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_37", "input text": "The location of Alpena County Regional Airport is Wilson Township, Alpena County, Michigan, USA, and has a runway length of 2744.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Appleton International Airport is 280 metres above sea level and has a runway length of 2439.0. It is operated from Outagamie County, Wisconsin.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Appleton International Airport\", \"runwayLength\", \"2439.0\"], [\"Appleton International Airport\", \"elevationAboveTheSeaLevel\", \"280\"], [\"Appleton International Airport\", \"operatingOrganisation\", \"Outagamie County, Wisconsin\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The location of Alpena County Regional Airport is Wilson Township, Alpena County, Michigan, USA, and has a runway length of 2744.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"location\", \"Wilson Township, Alpena County, Michigan, USA\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"The location of Alpena County Regional Airport is Wilson Township, Alpena County, Michigan, USA\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"runwayLength\", \"2744\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"and has a runway length of 2744.\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alpena County Regional Airport", "location", "Wilson Township, Alpena County, Michigan, USA"], "subject_type": "Airport", "object_type": "Place", "support": "The location of Alpena County Regional Airport is Wilson Township, Alpena County, Michigan, USA", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "runwayLength", "2744"], "subject_type": "Airport", "object_type": "number", "support": "and has a runway length of 2744.", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_38", "input text": "Located at Ícolo e Bengo, Angola International Airport is 159 metres above the sea level and has a runway length of 3,800 metres.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The Adolfo Suárez Madrid–Barajas Airport in Alcobendas is operated by ENAIRE and is 610m above sea level. It has a runway length of 3,500 and the runway name is 18L/36R.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Adolfo Suárez Madrid–Barajas Airport\", \"operatingOrganisation\", \"ENAIRE\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"location\", \"Alcobendas\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayLength\", \"3500.0\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"elevationAboveTheSeaLevel\", \"610.0\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayName\", \"18L/36R\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Located at Ícolo e Bengo, Angola International Airport is 159 metres above the sea level and has a runway length of 3,800 metres.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Angola International Airport\", \"elevationAboveTheSeaLevel\", \"159.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"Located at Ícolo e Bengo, Angola International Airport is 159 metres above the sea level\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Angola International Airport\", \"runwayLength\", \"3800.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"Located at Ícolo e Bengo, Angola International Airport has a runway length of 3,800 metres\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Angola International Airport", "elevationAboveTheSeaLevel", "159.0"], "subject_type": "Airport", "object_type": "number", "support": "Located at Ícolo e Bengo, Angola International Airport is 159 metres above the sea level", "confidence": 1.0}, {"triple": ["Angola International Airport", "runwayLength", "3800.0"], "subject_type": "Airport", "object_type": "number", "support": "Located at Ícolo e Bengo, Angola International Airport has a runway length of 3,800 metres", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_39", "input text": "Located in Ícolo e Bengo, Angola International Airport is 159 meters above sea level and has a runway length of 4000ft.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Adolfo Suárez Madrid–Barajas Airport is in Alcobendas and is operated by ENAIRE in which is in Madrid. The runway length of Adolfo Suárez Madrid–Barajas Airport is 4,349 and is named 14R/32L, Adolfo Suárez Madrid-Barajas Airport also has an elevation of 610.0 metres above sea level and a runway length of 4,349.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Adolfo Suárez Madrid–Barajas Airport\", \"operatingOrganisation\", \"ENAIRE\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"location\", \"Alcobendas\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayLength\", \"4349.0\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayName\", \"14R/32L\"], [\"ENAIRE\", \"city\", \"Madrid\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"elevationAboveTheSeaLevel\", \"610.0\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Located in Ícolo e Bengo, Angola International Airport is 159 meters above sea level and has a runway length of 4000ft.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Angola International Airport\", \"elevationAboveTheSeaLevel\", \"159\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"Located in Ícolo e Bengo, Angola International Airport is 159 meters above sea level\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Angola International Airport\", \"runwayLength\", \"4000ft\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"Located in Ícolo e Bengo, Angola International Airport is 159 meters above sea level and has a runway length of 4000ft\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Angola International Airport\", \"runwayLength\", \"4000\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"Located in Ícolo e Bengo, Angola International Airport is 159 meters above sea level and has a runway length of 4000ft\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Angola International Airport", "elevationAboveTheSeaLevel", "159"], "subject_type": "Airport", "object_type": "number", "support": "Located in Ícolo e Bengo, Angola International Airport is 159 meters above sea level", "confidence": 1.0}, {"triple": ["Angola International Airport", "runwayLength", "4000ft"], "subject_type": "Airport", "object_type": "number", "support": "Located in Ícolo e Bengo, Angola International Airport is 159 meters above sea level and has a runway length of 4000ft", "confidence": 1.0}, {"triple": ["Angola International Airport", "runwayLength", "4000"], "subject_type": "Airport", "object_type": "number", "support": "Located in Ícolo e Bengo, Angola International Airport is 159 meters above sea level and has a runway length of 4000ft", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_40", "input text": "At 159 meters above sea level, Angola International airport is located in Icolo e Bengo, in Angola.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Ashgabat is the location of Ashgabat International Airport which is elevated 211 metres above sea level, and has a runway that is 2989.0 metres long.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Ashgabat International Airport\", \"location\", \"Ashgabat\"], [\"Ashgabat International Airport\", \"runwayLength\", \"2989.0\"], [\"Ashgabat International Airport\", \"elevationAboveTheSeaLevelInMetres\", \"211\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"At 159 meters above sea level, Angola International airport is located in Icolo e Bengo, in Angola.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Angola International airport\", \"location\", \"Icolo e Bengo\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"At 159 meters above sea level, Angola International airport is located in Icolo e Bengo, in Angola.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Angola International airport\", \"elevationAboveTheSeaLevelInMetres\", \"159\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"At 159 meters above sea level, Angola International airport is located in Icolo e Bengo, in Angola.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Angola International airport\", \"country\", \"Angola\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Country\",\n      \"support\": \"in Angola.\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Angola International airport", "location", "Icolo e Bengo"], "subject_type": "Airport", "object_type": "City", "support": "At 159 meters above sea level, Angola International airport is located in Icolo e Bengo, in Angola.", "confidence": 1.0}, {"triple": ["Angola International airport", "elevationAboveTheSeaLevelInMetres", "159"], "subject_type": "Airport", "object_type": "number", "support": "At 159 meters above sea level, Angola International airport is located in Icolo e Bengo, in Angola.", "confidence": 1.0}, {"triple": ["Angola International airport", "country", "Angola"], "subject_type": "Airport", "object_type": "Country", "support": "in Angola.", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_41", "input text": "With a runway length of 3800 metres, Angola International Airport is located at Ícolo e Bengo, in Angola.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Located in Alcobendas, Adolfo Suárez Madrid–Barajas Airport has a runway length of 3500 metres and a runway named 18R/36L.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Adolfo Suárez Madrid–Barajas Airport\", \"location\", \"Alcobendas\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayName\", \"18R/36L\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayLength\", \"3500.0\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"With a runway length of 3800 metres, Angola International Airport is located at Ícolo e Bengo, in Angola.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Angola International Airport\", \"location\", \"Ícolo e Bengo\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"With a runway length of 3800 metres, Angola International Airport is located at Ícolo e Bengo, in Angola.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Angola International Airport\", \"runwayLength\", \"3800.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"With a runway length of 3800 metres, Angola International Airport is located at Ícolo e Bengo, in Angola.\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Angola International Airport", "location", "Ícolo e Bengo"], "subject_type": "Airport", "object_type": "Place", "support": "With a runway length of 3800 metres, Angola International Airport is located at Ícolo e Bengo, in Angola.", "confidence": 1.0}, {"triple": ["Angola International Airport", "runwayLength", "3800.0"], "subject_type": "Airport", "object_type": "number", "support": "With a runway length of 3800 metres, Angola International Airport is located at Ícolo e Bengo, in Angola.", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_42", "input text": "05L/23R is the name of the runway at Angola International airport in Icolo e Bengo, Angola.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Amsterdam Airport Schiphol serves the city of Amsterdam, it has a runway length of 3453.0 and is -3.3528 metres above sea level.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Amsterdam Airport Schiphol\", \"cityServed\", \"Amsterdam\"], [\"Amsterdam Airport Schiphol\", \"runwayLength\", \"3453.0\"], [\"Amsterdam Airport Schiphol\", \"elevationAboveTheSeaLevel\", \"-3.3528\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"05L/23R is the name of the runway at Angola International airport in Icolo e Bengo, Angola.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"05L/23R\", \"runwayName\", \"string\"],\n      \"subject_type\": \"Runway\",\n      \"object_type\": \"string\",\n      \"support\": \"\\\"05L/23R is the name of the runway at Angola International airport in Icolo e Bengo, Angola.\\\"\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Angola International airport\", \"location\", \"Icolo e Bengo, Angola\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"\\\"05L/23R is the name of the runway at Angola International airport in Icolo e Bengo, Angola.\\\"\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["05L/23R", "runwayName", "string"], "subject_type": "Runway", "object_type": "string", "support": "\"05L/23R is the name of the runway at Angola International airport in Icolo e Bengo, Angola.\"", "confidence": 1.0}, {"triple": ["Angola International airport", "location", "Icolo e Bengo, Angola"], "subject_type": "Airport", "object_type": "Place", "support": "\"05L/23R is the name of the runway at Angola International airport in Icolo e Bengo, Angola.\"", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_43", "input text": "Angola International Airport is located in Icolo e Bengo, Angolo, Luanda Province.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Antwerp International Airport serves the city of Antwerp which is in Belgium, where the capital is Brussels.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Antwerp International Airport\", \"cityServed\", \"Antwerp\"], [\"Antwerp\", \"country\", \"Belgium\"], [\"Belgium\", \"capital\", \"City of Brussels\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Angola International Airport is located in Icolo e Bengo, Angolo, Luanda Province.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Angola International Airport\", \"location\", \"Icolo e Bengo\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Angola International Airport is located in Icolo e Bengo\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Icolo e Bengo\", \"county\", \"Angola\"],\n      \"subject_type\": \"Place\",\n      \"object_type\": \"Country\",\n      \"support\": \"Icolo e Bengo, Angola\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Angola\", \"province\", \"Luanda Province\"],\n      \"subject_type\": \"Country\",\n      \"object_type\": \"Place\",\n      \"support\": \"Angola Province\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Angola International Airport", "location", "Icolo e Bengo"], "subject_type": "Airport", "object_type": "Place", "support": "Angola International Airport is located in Icolo e Bengo", "confidence": 1.0}, {"triple": ["Icolo e Bengo", "county", "Angola"], "subject_type": "Place", "object_type": "Country", "support": "Icolo e Bengo, Angola", "confidence": 1.0}, {"triple": ["Angola", "province", "Luanda Province"], "subject_type": "Country", "object_type": "Place", "support": "Angola Province", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_44", "input text": "The city of Luanda is served by Angola International Airport. This airport is is 159 meters above sea level and has a runway length of 4000 metres.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Al-Taqaddum Air Base, located 84 metres above sea level, serves the city of Fallujah and has a runway length of 4,019.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Al-Taqaddum Air Base\", \"runwayLength\", \"4019.0\"], [\"Al-Taqaddum Air Base\", \"cityServed\", \"Fallujah\"], [\"Al-Taqaddum Air Base\", \"elevationAboveTheSeaLevel\", \"84.0\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The city of Luanda is served by Angola International Airport. This airport is is 159 meters above sea level and has a runway length of 4000 metres.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Angola International Airport\", \"cityServed\", \"Luanda\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"The city of Luanda is served by Angola International Airport.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Angola International Airport\", \"elevationAboveTheSeaLevel\", \"159.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"This airport is is 159 meters above sea level\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Angola International Airport\", \"runwayLength\", \"4000.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"and has a runway length of 4000 metres.\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Angola International Airport", "cityServed", "Luanda"], "subject_type": "Airport", "object_type": "City", "support": "The city of Luanda is served by Angola International Airport.", "confidence": 1.0}, {"triple": ["Angola International Airport", "elevationAboveTheSeaLevel", "159.0"], "subject_type": "Airport", "object_type": "number", "support": "This airport is is 159 meters above sea level", "confidence": 1.0}, {"triple": ["Angola International Airport", "runwayLength", "4000.0"], "subject_type": "Airport", "object_type": "number", "support": "and has a runway length of 4000 metres.", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_45", "input text": "The 3rd runway at Ardmore Airport in New Zealand (which is 34 meters above sea level) is made of Poaceae and has a length of 518.0.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The runway length at Adolfo Suarez Madrid-Barajas airport, which is run by ENAIRE, is 3500 and the airport is 610 metres above sea level.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Adolfo Suárez Madrid–Barajas Airport\", \"operatingOrganisation\", \"ENAIRE\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayLength\", \"3500.0\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"elevationAboveTheSeaLevel\", \"610.0\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The 3rd runway at Ardmore Airport in New Zealand (which is 34 meters above sea level) is made of Poaceae and has a length of 518.0.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Ardmore Airport\", \"runwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The 3rd runway at Ardmore Airport in New Zealand (which is 34 meters above sea level) is made of Poaceae\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Ardmore Airport\", \"elevationAboveTheSeaLevel\", \"34.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"The 3rd runway at Ardmore Airport in New Zealand (which is 34 meters above sea level)\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Ardmore Airport\", \"runwayLength\", \"518.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"The 3rd runway at Ardmore Airport in New Zealand is 518.0\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Ardmore Airport", "runwaySurfaceType", "Poaceae"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "The 3rd runway at Ardmore Airport in New Zealand (which is 34 meters above sea level) is made of Poaceae", "confidence": 1.0}, {"triple": ["Ardmore Airport", "elevationAboveTheSeaLevel", "34.0"], "subject_type": "Airport", "object_type": "number", "support": "The 3rd runway at Ardmore Airport in New Zealand (which is 34 meters above sea level)", "confidence": 1.0}, {"triple": ["Ardmore Airport", "runwayLength", "518.0"], "subject_type": "Airport", "object_type": "number", "support": "The 3rd runway at Ardmore Airport in New Zealand is 518.0", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_46", "input text": "At the Ardmore airport in New Zealand, the 3rd runway is made from Poaceae which belongs to the flowering plants division and is in the class of Monocotyledon.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The 18L/36R runway of the Allama Iqbal International airport is located in Punjab Pakistan and has a length of 33310.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Allama Iqbal International Airport\", \"runwayLength\", \"3310.0\"], [\"Allama Iqbal International Airport\", \"location\", \"Punjab, Pakistan\"], [\"Allama Iqbal International Airport\", \"runwayName\", \"18L/36R\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"At the Ardmore airport in New Zealand, the 3rd runway is made from Poaceae which belongs to the flowering plants division and is in the class of Monocotyledon.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Ardmore airport\", \"runwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The 3rd runway is made from Poaceae\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Ardmore airport\", \"class\", \"Monocotyledon\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Class\",\n      \"support\": \"Poaceae belongs to the flowering plants division and is in the class of Monocotyledon\",\n      \"confidence\": 0.8\n    },\n    {\n      \"triple\": [\"Ardmore airport\", \"location\", \"New Zealand\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Country\",\n      \"support\": \"At the Ardmore airport\",\n      \"confidence\": 0.7\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Ardmore airport", "runwaySurfaceType", "Poaceae"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "The 3rd runway is made from Poaceae", "confidence": 1.0}, {"triple": ["Ardmore airport", "class", "Monocotyledon"], "subject_type": "Airport", "object_type": "Class", "support": "Poaceae belongs to the flowering plants division and is in the class of Monocotyledon", "confidence": 0.8}, {"triple": ["Ardmore airport", "location", "New Zealand"], "subject_type": "Airport", "object_type": "Country", "support": "At the Ardmore airport", "confidence": 0.7}]}}}
{"id": "ont_3_airport_test_47", "input text": "The 3rd runway at Ardmore Airport (New Zealand) is made of Poaceae which is class as monocotyledon and part of the commelinids order.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The 18L/36R runway of the Allama Iqbal International airport is located in Punjab Pakistan and has a length of 33310.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Allama Iqbal International Airport\", \"runwayLength\", \"3310.0\"], [\"Allama Iqbal International Airport\", \"location\", \"Punjab, Pakistan\"], [\"Allama Iqbal International Airport\", \"runwayName\", \"18L/36R\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The 3rd runway at Ardmore Airport (New Zealand) is made of Poaceae which is class as monocotyledon and part of the commelinids order.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Ardmore Airport (New Zealand)\", \"runwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The 3rd runway at Ardmore Airport (New Zealand) is made of Poaceae\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Poaceae\", \"class\", \"monocotyledon\"],\n      \"subject_type\": \"RunwaySurfaceType\",\n      \"object_type\": \"Class\",\n      \"support\": \"which is class as monocotyledon\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Poaceae\", \"partOf\", \"commelinids order\"],\n      \"subject_type\": \"RunwaySurfaceType\",\n      \"object_type\": \"Class\",\n      \"support\": \"and part of the commelinids order\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Ardmore Airport (New Zealand)", "runwaySurfaceType", "Poaceae"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "The 3rd runway at Ardmore Airport (New Zealand) is made of Poaceae", "confidence": 1.0}, {"triple": ["Poaceae", "class", "monocotyledon"], "subject_type": "RunwaySurfaceType", "object_type": "Class", "support": "which is class as monocotyledon", "confidence": 1.0}, {"triple": ["Poaceae", "partOf", "commelinids order"], "subject_type": "RunwaySurfaceType", "object_type": "Class", "support": "and part of the commelinids order", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_48", "input text": "Ardmore Airport (New Zealand)'s 3rd runway surface type is Poaceae which is of the poales order and the class of Monocotyledon.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The 18L/36R runway of the Allama Iqbal International airport is located in Punjab Pakistan and has a length of 33310.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Allama Iqbal International Airport\", \"runwayLength\", \"3310.0\"], [\"Allama Iqbal International Airport\", \"location\", \"Punjab, Pakistan\"], [\"Allama Iqbal International Airport\", \"runwayName\", \"18L/36R\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Ardmore Airport (New Zealand)'s 3rd runway surface type is Poaceae which is of the poales order and the class of Monocotyledon.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Ardmore Airport (New Zealand)\", \"3rdRunwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"Ardmore Airport (New Zealand)'s 3rd runway surface type is Poaceae\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Ardmore Airport (New Zealand)\", \"class\", \"Monocotyledon\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Class\",\n      \"support\": \"the class of Monocotyledon\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Poaceae\", \"order\", \"Poales\"],\n      \"subject_type\": \"RunwaySurfaceType\",\n      \"object_type\": \"Division\",\n      \"support\": \"Poales order\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Ardmore Airport (New Zealand)", "3rdRunwaySurfaceType", "Poaceae"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "Ardmore Airport (New Zealand)'s 3rd runway surface type is Poaceae", "confidence": 1.0}, {"triple": ["Ardmore Airport (New Zealand)", "class", "Monocotyledon"], "subject_type": "Airport", "object_type": "Class", "support": "the class of Monocotyledon", "confidence": 1.0}, {"triple": ["Poaceae", "order", "Poales"], "subject_type": "RunwaySurfaceType", "object_type": "Division", "support": "Poales order", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_49", "input text": "In New Zealand, the 3rd runway at Ardmore Airport is made of Poaceae, a plant that belongs to the division of flowering plants and is part of the Commelinids order.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The 18L/36R runway of the Allama Iqbal International airport is located in Punjab Pakistan and has a length of 33310.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Allama Iqbal International Airport\", \"runwayLength\", \"3310.0\"], [\"Allama Iqbal International Airport\", \"location\", \"Punjab, Pakistan\"], [\"Allama Iqbal International Airport\", \"runwayName\", \"18L/36R\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"In New Zealand, the 3rd runway at Ardmore Airport is made of Poaceae, a plant that belongs to the division of flowering plants and is part of the Commelinids order.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Ardmore Airport\", \"runwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The 3rd runway at Ardmore Airport is made of Poaceae\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Poaceae\", \"belongsTo\", \"Division of flowering plants\"],\n      \"subject_type\": \"RunwaySurfaceType\",\n      \"object_type\": \"Division\",\n      \"support\": \"Poaceae belongs to the division of flowering plants\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Poaceae\", \"partOf\", \"Commelinids order\"],\n      \"subject_type\": \"RunwaySurfaceType\",\n      \"object_type\": \"Order\",\n      \"support\": \"Poaceae is part of the Commelinids order\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Ardmore Airport", "runwaySurfaceType", "Poaceae"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "The 3rd runway at Ardmore Airport is made of Poaceae", "confidence": 1.0}, {"triple": ["Poaceae", "belongsTo", "Division of flowering plants"], "subject_type": "RunwaySurfaceType", "object_type": "Division", "support": "Poaceae belongs to the division of flowering plants", "confidence": 1.0}, {"triple": ["Poaceae", "partOf", "Commelinids order"], "subject_type": "RunwaySurfaceType", "object_type": "Order", "support": "Poaceae is part of the Commelinids order", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_50", "input text": "The Ardmore Airport in New Zealand, located 34 meters above sea level, has a runway length of 1411.0 and the third runway is made of Poaceae.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Adolfo Suárez Madrid-Barajas Airport (in Alcobendas), has a runway named 14L/32R and a runway that is 3500 metres long.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Adolfo Suárez Madrid–Barajas Airport\", \"location\", \"Alcobendas\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayLength\", \"3500.0\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayName\", \"14L/32R\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The Ardmore Airport in New Zealand, located 34 meters above sea level, has a runway length of 1411.0 and the third runway is made of Poaceae.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"The Ardmore Airport\", \"location\", \"New Zealand\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Country\",\n      \"support\": \"The Ardmore Airport in New Zealand\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"The Ardmore Airport\", \"elevationAboveTheSeaLevel\", \"34.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"located 34 meters above sea level\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"The Ardmore Airport\", \"runwayLength\", \"1411.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"has a runway length of 1411.0\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"The 3rd runway of The Ardmore Airport\", \"runwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Runway\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"the third runway is made of Poaceae\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["The Ardmore Airport", "location", "New Zealand"], "subject_type": "Airport", "object_type": "Country", "support": "The Ardmore Airport in New Zealand", "confidence": 1.0}, {"triple": ["The Ardmore Airport", "elevationAboveTheSeaLevel", "34.0"], "subject_type": "Airport", "object_type": "number", "support": "located 34 meters above sea level", "confidence": 1.0}, {"triple": ["The Ardmore Airport", "runwayLength", "1411.0"], "subject_type": "Airport", "object_type": "number", "support": "has a runway length of 1411.0", "confidence": 1.0}, {"triple": ["The 3rd runway of The Ardmore Airport", "runwaySurfaceType", "Poaceae"], "subject_type": "Runway", "object_type": "RunwaySurfaceType", "support": "the third runway is made of Poaceae", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_51", "input text": "New Zealand's Ardmore Airport; is 34.0 metres above sea level, has a runway length of 597.0 metres and its 3rd runway surface type is Poaceae.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The runway length at Adolfo Suarez Madrid-Barajas airport, which is run by ENAIRE, is 3500 and the airport is 610 metres above sea level.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Adolfo Suárez Madrid–Barajas Airport\", \"operatingOrganisation\", \"ENAIRE\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayLength\", \"3500.0\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"elevationAboveTheSeaLevel\", \"610.0\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"New Zealand's Ardmore Airport; is 34.0 metres above sea level, has a runway length of 597.0 metres and its 3rd runway surface type is Poaceae.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"New Zealand's Ardmore Airport\", \"elevationAboveTheSeaLevel\", \"34.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"\\\"New Zealand's Ardmore Airport; is 34.0 metres above sea level,\\\"\"\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"New Zealand's Ardmore Airport\", \"runwayLength\", \"597.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"\\\"has a runway length of 597.0 metres\\\"\"\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"New Zealand's Ardmore Airport\", \"3rdRunwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"\\\"its 3rd runway surface type is Poaceae.\\\"\"\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": null}}
{"id": "ont_3_airport_test_52", "input text": "Athens International Airport serves the city of Athens which is in Greece where Nikos Voutsis is the leader.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Antwerp International Airport serves the city of Antwerp in Belgium where the leader is Philippe of Belgium.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Belgium\", \"leader\", \"Philippe of Belgium\"], [\"Antwerp International Airport\", \"cityServed\", \"Antwerp\"], [\"Antwerp\", \"country\", \"Belgium\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Athens International Airport serves the city of Athens which is in Greece where Nikos Voutsis is the leader.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Athens International Airport\", \"cityServed\", \"Athens\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Athens International Airport serves the city of Athens\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Athens\", \"country\", \"Greece\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"Country\",\n      \"support\": \"which is in Greece\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Athens International Airport\", \"leader\", \"Nikos Voutsis\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Person\",\n      \"support\": \"where Nikos Voutsis is the leader.\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Athens International Airport", "cityServed", "Athens"], "subject_type": "Airport", "object_type": "City", "support": "Athens International Airport serves the city of Athens", "confidence": 1.0}, {"triple": ["Athens", "country", "Greece"], "subject_type": "City", "object_type": "Country", "support": "which is in Greece", "confidence": 1.0}, {"triple": ["Athens International Airport", "leader", "Nikos Voutsis"], "subject_type": "Airport", "object_type": "Person", "support": "where Nikos Voutsis is the leader.", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_53", "input text": "Athens is located in Greece and is served by the Athens International Airport. The leader of Greece is Prokopis Pavlopoulos.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Antwerp International Airport serves the city of Antwerp in Belgium where the leader is Philippe of Belgium.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Belgium\", \"leader\", \"Philippe of Belgium\"], [\"Antwerp International Airport\", \"cityServed\", \"Antwerp\"], [\"Antwerp\", \"country\", \"Belgium\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Athens is located in Greece and is served by the Athens International Airport. The leader of Greece is Prokopis Pavlopoulos.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Athens\", \"city\", \"Athens\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"City\",\n      \"support\": \"Athens is located in Greece and is served by the Athens International Airport.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Athens International Airport\", \"cityServed\", \"Athens\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Athens International Airport serves the city of Athens\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Greece\", \"country\", \"Greece\"],\n      \"subject_type\": \"Country\",\n      \"object_type\": \"Country\",\n      \"support\": \"Athens is located in Greece\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Prokopis Pavlopoulos\", \"leader\", \"Greece\"],\n      \"subject_type\": \"Person\",\n      \"object_type\": \"Country\",\n      \"support\": \"The leader of Greece is Prokopis Pavlopoulos.\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Athens", "city", "Athens"], "subject_type": "City", "object_type": "City", "support": "Athens is located in Greece and is served by the Athens International Airport.", "confidence": 1.0}, {"triple": ["Athens International Airport", "cityServed", "Athens"], "subject_type": "Airport", "object_type": "City", "support": "Athens International Airport serves the city of Athens", "confidence": 1.0}, {"triple": ["Greece", "country", "Greece"], "subject_type": "Country", "object_type": "Country", "support": "Athens is located in Greece", "confidence": 1.0}, {"triple": ["Prokopis Pavlopoulos", "leader", "Greece"], "subject_type": "Person", "object_type": "Country", "support": "The leader of Greece is Prokopis Pavlopoulos.", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_54", "input text": "Athens is served by the Athens International Airport located in Spata at 94 metres above sea level.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Ashgabat is the location of Ashgabat International Airport which is elevated 211 metres above sea level and has a runway length of 900.0 metres.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Ashgabat International Airport\", \"location\", \"Ashgabat\"], [\"Ashgabat International Airport\", \"elevationAboveTheSeaLevelInMetres\", \"211\"], [\"Ashgabat International Airport\", \"runwayLength\", \"900.0\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Athens is served by the Athens International Airport located in Spata at 94 metres above sea level.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Athens International Airport\", \"location\", \"Spata\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Athens is served by the Athens International Airport located in Spata\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Athens International Airport\", \"elevationAboveTheSeaLevelInMetres\", \"94\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"Athens International Airport located in Spata at 94 metres above sea level\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Athens International Airport", "location", "Spata"], "subject_type": "Airport", "object_type": "Place", "support": "Athens is served by the Athens International Airport located in Spata", "confidence": 1.0}, {"triple": ["Athens International Airport", "elevationAboveTheSeaLevelInMetres", "94"], "subject_type": "Airport", "object_type": "number", "support": "Athens International Airport located in Spata at 94 metres above sea level", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_55", "input text": "With a runway length of 3800 metres, Athens International Airport is in Spata, and serves the city of Athens.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Located in Alcobendas, Adolfo Suárez Madrid–Barajas Airport has a runway length of 3500 metres and a runway named 18R/36L.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Adolfo Suárez Madrid–Barajas Airport\", \"location\", \"Alcobendas\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayName\", \"18R/36L\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayLength\", \"3500.0\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"With a runway length of 3800 metres, Athens International Airport is in Spata, and serves the city of Athens.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Athens International Airport\", \"location\", \"Spata\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"With a runway length of 3800 metres, Athens International Airport is in Spata,\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Athens International Airport\", \"cityServed\", \"Athens\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"and serves the city of Athens.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Athens International Airport\", \"runwayLength\", \"3800.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"With a runway length of 3800 metres,\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Athens International Airport", "location", "Spata"], "subject_type": "Airport", "object_type": "Place", "support": "With a runway length of 3800 metres, Athens International Airport is in Spata,", "confidence": 1.0}, {"triple": ["Athens International Airport", "cityServed", "Athens"], "subject_type": "Airport", "object_type": "City", "support": "and serves the city of Athens.", "confidence": 1.0}, {"triple": ["Athens International Airport", "runwayLength", "3800.0"], "subject_type": "Airport", "object_type": "number", "support": "With a runway length of 3800 metres,", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_56", "input text": "With a runway length of 4000.0 metres, Athens International Airport is located in Spata and serves the city of Athens.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The 14L/32R runway of the Adolfo Suarez Madrid-Barajas Airport in Madrid has a length of 4100.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayLength\", \"4100.0\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"location\", \"Madrid\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayName\", \"14L/32R\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"With a runway length of 4000.0 metres, Athens International Airport is located in Spata and serves the city of Athens.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Athens International Airport\", \"runwayLength\", \"4000.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"With a runway length of 4000.0 metres\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Athens International Airport\", \"location\", \"Spata\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Athens International Airport is located in Spata\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Athens International Airport\", \"cityServed\", \"Athens\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Athens International Airport serves the city of Athens\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Athens International Airport\", \"country\", \"Greece\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Country\",\n      // The text does not explicitly mention the country, but it's implied since Athens is in Greece.\n      \"support\": \"Implied from the fact that Athens is in Greece\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": null}}
{"id": "ont_3_airport_test_57", "input text": "Agra Airport is operated by the Indian Air Force which uses HAL Light Combat Helicopter (aircraft helicopter) and the Boeing C-17 Globemaster III (a transport aircraft).", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Allama Iqbal International airport is located in Punjab Pakistan and is operated by Pakistan Civil Aviation Authority headquartered at Jinnah International Airport.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Allama Iqbal International Airport\", \"operatingOrganisation\", \"Pakistan Civil Aviation Authority\"], [\"Pakistan Civil Aviation Authority\", \"headquarter\", \"Jinnah International Airport\"], [\"Allama Iqbal International Airport\", \"location\", \"Punjab, Pakistan\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Agra Airport is operated by the Indian Air Force which uses HAL Light Combat Helicopter (aircraft helicopter) and the Boeing C-17 Globemaster III (a transport aircraft).\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Agra Airport\", \"operator\", \"Indian Air Force\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Organisation\",\n      \"support\": \"Indian Air Force which uses HAL Light Combat Helicopter (aircraft helicopter) and the Boeing C-17 Globemaster III (a transport aircraft).\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Indian Air Force\", \"aircraft\", \"HAL Light Combat Helicopter\"],\n      \"subject_type\": \"Organisation\",\n      \"object_type\": \"Aircraft\",\n      \"support\": \"Indian Air Force which uses HAL Light Combat Helicopter (aircraft helicopter) and the Boeing C-17 Globemaster III (a transport aircraft).\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Indian Air Force\", \"aircraft\", \"Boeing C-17 Globemaster III\"],\n      \"subject_type\": \"Organisation\",\n      \"object_type\": \"Aircraft\",\n      \"support\": \"Indian Air Force which uses HAL Light Combat Helicopter (aircraft helicopter) and the Boeing C-17 Globemaster III (a transport aircraft).\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Boeing C-17 Globemaster III\", \"type\", \"transportAircraft\"],\n      \"subject_type\": \"Aircraft\",\n      \"object_type\": \"Aircraft\",\n      \"support\": \"Boeing C-17 Globemaster III (a transport aircraft).\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Agra Airport", "operator", "Indian Air Force"], "subject_type": "Airport", "object_type": "Organisation", "support": "Indian Air Force which uses HAL Light Combat Helicopter (aircraft helicopter) and the Boeing C-17 Globemaster III (a transport aircraft).", "confidence": 1.0}, {"triple": ["Indian Air Force", "aircraft", "HAL Light Combat Helicopter"], "subject_type": "Organisation", "object_type": "Aircraft", "support": "Indian Air Force which uses HAL Light Combat Helicopter (aircraft helicopter) and the Boeing C-17 Globemaster III (a transport aircraft).", "confidence": 1.0}, {"triple": ["Indian Air Force", "aircraft", "Boeing C-17 Globemaster III"], "subject_type": "Organisation", "object_type": "Aircraft", "support": "Indian Air Force which uses HAL Light Combat Helicopter (aircraft helicopter) and the Boeing C-17 Globemaster III (a transport aircraft).", "confidence": 1.0}, {"triple": ["Boeing C-17 Globemaster III", "type", "transportAircraft"], "subject_type": "Aircraft", "object_type": "Aircraft", "support": "Boeing C-17 Globemaster III (a transport aircraft).", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_58", "input text": "Afonso Pena International airport is located 911 metres above sea level and operated by Infraero located in Brasilia.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Adolfo Suarez Madrid-Barajas airport is located at Madrid, Paracuellos de Jarama, San Sebastián de los Reyes and Alcobendas. It is operated by ENAIRE and is 610 metres above sea level.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Adolfo Suárez Madrid–Barajas Airport\", \"operatingOrganisation\", \"ENAIRE\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"elevationAboveTheSeaLevel\", \"610.0\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"location\", \"Madrid, Paracuellos de Jarama, San Sebastián de los Reyes and Alcobendas\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Afonso Pena International airport is located 911 metres above sea level and operated by Infraero located in Brasilia.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Afonso Pena International airport\", \"elevationAboveTheSeaLevel\", \"911.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"Afonso Pena International airport is located 911 metres above sea level\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Infraero\", \"operator\", \"Afonso Pena International airport\"],\n      \"subject_type\": \"Organisation\",\n      \"object_type\": \"Airport\",\n      \"support\": \"operated by Infraero\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Infraero\", \"location\", \"Brasilia\"],\n      \"subject_type\": \"Organisation\",\n      \"object_type\": \"City\",\n      \"support\": \"located in Brasilia\",\n      \"confidence\": 0.75\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Afonso Pena International airport", "elevationAboveTheSeaLevel", "911.0"], "subject_type": "Airport", "object_type": "number", "support": "Afonso Pena International airport is located 911 metres above sea level", "confidence": 1.0}, {"triple": ["Infraero", "operator", "Afonso Pena International airport"], "subject_type": "Organisation", "object_type": "Airport", "support": "operated by Infraero", "confidence": 1.0}, {"triple": ["Infraero", "location", "Brasilia"], "subject_type": "Organisation", "object_type": "City", "support": "located in Brasilia", "confidence": 0.75}]}}}
{"id": "ont_3_airport_test_59", "input text": "In the class Monocotyledon, and belonging to the order Poales is Poaceae which is the surface type of the second runway of Ardmore Airport, New Zealand.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Bedford Aerodrome is located in Thurleigh, 83.2 meters above sea level. This airport serves the Bedford Autodrome and is operated by MotorSport Vision. The runway is 1095 meters long. The ICAO location identifier for Bedford Aerodrome is EGBF.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Bedford Aerodrome\", \"operatingOrganisation\", \"MotorSport Vision\"], [\"Bedford Aerodrome\", \"runwayLength\", \"1095.0\"], [\"Bedford Aerodrome\", \"cityServed\", \"Bedford Autodrome\"], [\"Bedford Aerodrome\", \"location\", \"Thurleigh\"], [\"Bedford Aerodrome\", \"icaoLocationIdentifier\", \"EGBF\"], [\"Bedford Aerodrome\", \"elevationAboveTheSeaLevel\", \"83.2104\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"In the class Monocotyledon, and belonging to the order Poales is Poaceae which is the surface type of the second runway of Ardmore Airport, New Zealand.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Poaceae\", \"runwaySurfaceType\", \"Ardmore Airport\"],\n      \"subject_type\": \"Grass\",\n      \"object_type\": \"Airport\",\n      \"support\": \"Poaceae which is the surface type of the second runway of Ardmore Airport\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Ardmore Airport\", \"order\", \"Poales\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Class\",\n      \"support\": \"Poaceae which is the surface type of the second runway of Ardmore Airport, belonging to the order Poales\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Ardmore Airport\", \"runwaySurfaceType\", \"2ndRunway\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Runway\",\n      \"support\": \"Poaceae which is the surface type of the second runway of Ardmore Airport\",\n      \"confidence\": 0.5\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Poaceae", "runwaySurfaceType", "Ardmore Airport"], "subject_type": "Grass", "object_type": "Airport", "support": "Poaceae which is the surface type of the second runway of Ardmore Airport", "confidence": 1.0}, {"triple": ["Ardmore Airport", "order", "Poales"], "subject_type": "Airport", "object_type": "Class", "support": "Poaceae which is the surface type of the second runway of Ardmore Airport, belonging to the order Poales", "confidence": 1.0}, {"triple": ["Ardmore Airport", "runwaySurfaceType", "2ndRunway"], "subject_type": "Airport", "object_type": "Runway", "support": "Poaceae which is the surface type of the second runway of Ardmore Airport", "confidence": 0.5}]}}}
{"id": "ont_3_airport_test_60", "input text": "The 1st runway at Alderney Airport is made from Poaceae which belongs to the division of flowering plants and is of the class Monocotyledon.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The Bedford Aerodrome runway name is 08/26, it is 1095 long and the surface is made of concrete, it is also 83.2104 meters above sea level. The ICAO location identifier for the aerodrome is EGBF.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Bedford Aerodrome\", \"runwayLength\", \"1095.0\"], [\"Bedford Aerodrome\", \"icaoLocationIdentifier\", \"EGBF\"], [\"Bedford Aerodrome\", \"elevationAboveTheSeaLevel\", \"83.2104\"], [\"Bedford Aerodrome\", \"runwayName\", \"08/26\"], [\"Bedford Aerodrome\", \"runwaySurfaceType\", \"Concrete\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The 1st runway at Alderney Airport is made from Poaceae which belongs to the division of flowering plants and is of the class Monocotyledon.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alderney Airport\", \"runwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The 1st runway at Alderney Airport is made from Poaceae\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Poaceae\", \"class\", \"Monocotyledon\"],\n      \"subject_type\": \"RunwaySurfaceType\",\n      \"object_type\": \"Class\",\n      \"support\": \"which belongs to the division of flowering plants and is of the class Monocotyledon\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alderney Airport", "runwaySurfaceType", "Poaceae"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "The 1st runway at Alderney Airport is made from Poaceae", "confidence": 1.0}, {"triple": ["Poaceae", "class", "Monocotyledon"], "subject_type": "RunwaySurfaceType", "object_type": "Class", "support": "which belongs to the division of flowering plants and is of the class Monocotyledon", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_61", "input text": "Poaceae, of the Commelinids order, belongs to the division of flowering plants and its the surface of the 1st runway at Alderney airport.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Amsterdam Airport Schiphol serves the city of Amsterdam, it has a runway length of 3453.0 and is -3.3528 metres above sea level.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Amsterdam Airport Schiphol\", \"cityServed\", \"Amsterdam\"], [\"Amsterdam Airport Schiphol\", \"runwayLength\", \"3453.0\"], [\"Amsterdam Airport Schiphol\", \"elevationAboveTheSeaLevel\", \"-3.3528\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Poaceae, of the Commelinids order, belongs to the division of flowering plants and its the surface of the 1st runway at Alderney airport.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Poaceae\", \"belongsTo\", \"division\"],\n      \"subject_type\": \"Plant\",\n      \"object_type\": \"Division\",\n      \"support\": \"Poaceae, of the Commelinids order, belongs to the division of flowering plants\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"1st runway at Alderney airport\", \"runwaySurfaceType\", \"RunwaySurfaceType\"],\n      \"subject_type\": \"Runway\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"the surface of the 1st runway at Alderney airport\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Poaceae", "belongsTo", "division"], "subject_type": "Plant", "object_type": "Division", "support": "Poaceae, of the Commelinids order, belongs to the division of flowering plants", "confidence": 1.0}, {"triple": ["1st runway at Alderney airport", "runwaySurfaceType", "RunwaySurfaceType"], "subject_type": "Runway", "object_type": "RunwaySurfaceType", "support": "the surface of the 1st runway at Alderney airport", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_62", "input text": "The 1st runway at Alderney Airport is made from Poaceae which belongs to the division of flowering plants and the order poales.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Amsterdam Airport Schiphol serves the city of Amsterdam, it has a runway length of 3453.0 and is -3.3528 metres above sea level.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Amsterdam Airport Schiphol\", \"cityServed\", \"Amsterdam\"], [\"Amsterdam Airport Schiphol\", \"runwayLength\", \"3453.0\"], [\"Amsterdam Airport Schiphol\", \"elevationAboveTheSeaLevel\", \"-3.3528\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The 1st runway at Alderney Airport is made from Poaceae which belongs to the division of flowering plants and the order poales.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alderney Airport\", \"1stRunwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The 1st runway at Alderney Airport is made from Poaceae\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Poaceae\", \"belongsTo\", \"Division\"],\n      \"subject_type\": \"RunwaySurfaceType\",\n      \"object_type\": \"Division\",\n      \"support\": \"which belongs to the division of flowering plants and the order poales\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Poaceae\", \"order\", \"Poales\"],\n      \"subject_type\": \"RunwaySurfaceType\",\n      \"object_type\": \"Order\",\n      \"support\": \"which belongs to the division of flowering plants and the order poales\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alderney Airport", "1stRunwaySurfaceType", "Poaceae"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "The 1st runway at Alderney Airport is made from Poaceae", "confidence": 1.0}, {"triple": ["Poaceae", "belongsTo", "Division"], "subject_type": "RunwaySurfaceType", "object_type": "Division", "support": "which belongs to the division of flowering plants and the order poales", "confidence": 1.0}, {"triple": ["Poaceae", "order", "Poales"], "subject_type": "RunwaySurfaceType", "object_type": "Order", "support": "which belongs to the division of flowering plants and the order poales", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_63", "input text": "Poaceae which is of the Poales order belongs to the division of flowering plants, the 2nd runway at Ardmore Airport (New Zealand) is made of Poaceae.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Bedford Aerodrome is located in Thurleigh, 83.2 meters above sea level. This airport serves the Bedford Autodrome and is operated by MotorSport Vision. The runway is 1095 meters long. The ICAO location identifier for Bedford Aerodrome is EGBF.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Bedford Aerodrome\", \"operatingOrganisation\", \"MotorSport Vision\"], [\"Bedford Aerodrome\", \"runwayLength\", \"1095.0\"], [\"Bedford Aerodrome\", \"cityServed\", \"Bedford Autodrome\"], [\"Bedford Aerodrome\", \"location\", \"Thurleigh\"], [\"Bedford Aerodrome\", \"icaoLocationIdentifier\", \"EGBF\"], [\"Bedford Aerodrome\", \"elevationAboveTheSeaLevel\", \"83.2104\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Poaceae which is of the Poales order belongs to the division of flowering plants, the 2nd runway at Ardmore Airport (New Zealand) is made of Poaceae.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Poaceae\", \"runwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Plant\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The 2nd runway at Ardmore Airport (New Zealand) is made of Poaceae.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Poaceae\", \"belongsTo\", \"Division\"],\n      \"subject_type\": \"Plant\",\n      \"object_type\": \"Division\",\n      \"support\": \"Poaceae which is of the Poales order belongs to the division of flowering plants\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Ardmore Airport (New Zealand)\", \"runwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The 2nd runway at Ardmore Airport (New Zealand) is made of Poaceae.\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Poaceae", "runwaySurfaceType", "Poaceae"], "subject_type": "Plant", "object_type": "RunwaySurfaceType", "support": "The 2nd runway at Ardmore Airport (New Zealand) is made of Poaceae.", "confidence": 1.0}, {"triple": ["Poaceae", "belongsTo", "Division"], "subject_type": "Plant", "object_type": "Division", "support": "Poaceae which is of the Poales order belongs to the division of flowering plants", "confidence": 1.0}, {"triple": ["Ardmore Airport (New Zealand)", "runwaySurfaceType", "Poaceae"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "The 2nd runway at Ardmore Airport (New Zealand) is made of Poaceae.", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_64", "input text": "The 2nd runway at Ardmore Airport (New Zealand) is made of Poaceae which belongs to the division of flowering plants and the order of Commelinids.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Bedford Aerodrome is located in Thurleigh, 83.2 meters above sea level. This airport serves the Bedford Autodrome and is operated by MotorSport Vision. The runway is 1095 meters long. The ICAO location identifier for Bedford Aerodrome is EGBF.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Bedford Aerodrome\", \"operatingOrganisation\", \"MotorSport Vision\"], [\"Bedford Aerodrome\", \"runwayLength\", \"1095.0\"], [\"Bedford Aerodrome\", \"cityServed\", \"Bedford Autodrome\"], [\"Bedford Aerodrome\", \"location\", \"Thurleigh\"], [\"Bedford Aerodrome\", \"icaoLocationIdentifier\", \"EGBF\"], [\"Bedford Aerodrome\", \"elevationAboveTheSeaLevel\", \"83.2104\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The 2nd runway at Ardmore Airport (New Zealand) is made of Poaceae which belongs to the division of flowering plants and the order of Commelinids.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Ardmore Airport (New Zealand)\", \"runwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The 2nd runway at Ardmore Airport (New Zealand) is made of Poaceae\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Poaceae\", \"belongsTo\", \"Division of flowering plants\"],\n      \"subject_type\": \"RunwaySurfaceType\",\n      \"object_type\": \"Division\",\n      \"support\": \"which belongs to the division of flowering plants\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Poaceae\", \"belongsTo\", \"Order of Commelinids\"],\n      \"subject_type\": \"RunwaySurfaceType\",\n      \"object_type\": \"Order\",\n      \"support\": \"and the order of Commelinids.\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Ardmore Airport (New Zealand)", "runwaySurfaceType", "Poaceae"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "The 2nd runway at Ardmore Airport (New Zealand) is made of Poaceae", "confidence": 1.0}, {"triple": ["Poaceae", "belongsTo", "Division of flowering plants"], "subject_type": "RunwaySurfaceType", "object_type": "Division", "support": "which belongs to the division of flowering plants", "confidence": 1.0}, {"triple": ["Poaceae", "belongsTo", "Order of Commelinids"], "subject_type": "RunwaySurfaceType", "object_type": "Order", "support": "and the order of Commelinids.", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_65", "input text": "Saranac Lake, New York, part of Harrietstown, New York, United States, is served by Adirondack Regional Airport.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The Atlantic City International Airport is operated by the Port Authority of New York and New Jersey which serves the region of New Jersey and is based in New York.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Atlantic City International Airport\", \"operatingOrganisation\", \"Port Authority of New York and New Jersey\"], [\"Port Authority of New York and New Jersey\", \"regionServed\", \"New Jersey\"], [\"Port Authority of New York and New Jersey\", \"headquarter\", \"New York\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Saranac Lake, New York, part of Harrietstown, New York, United States, is served by Adirondack Regional Airport.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Saranac Lake\", \"cityServed\", \"Adirondack Regional Airport\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"Airport\",\n      \"support\": \"Saranac Lake, New York, part of Harrietstown, New York, United States, is served by Adirondack Regional Airport.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Adirondack Regional Airport\", \"location\", \"Harrietstown, New York\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Saranac Lake, New York, part of Harrietstown, New York, United States, is served by Adirondack Regional Airport.\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Adirondack Regional Airport\", \"country\", \"United States\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Country\",\n      \"support\": \"Saranac Lake, New York, part of Harrietstown, New York, United States, is served by Adirondack Regional Airport.\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Saranac Lake", "cityServed", "Adirondack Regional Airport"], "subject_type": "City", "object_type": "Airport", "support": "Saranac Lake, New York, part of Harrietstown, New York, United States, is served by Adirondack Regional Airport.", "confidence": 1.0}, {"triple": ["Adirondack Regional Airport", "location", "Harrietstown, New York"], "subject_type": "Airport", "object_type": "Place", "support": "Saranac Lake, New York, part of Harrietstown, New York, United States, is served by Adirondack Regional Airport.", "confidence": 1.0}, {"triple": ["Adirondack Regional Airport", "country", "United States"], "subject_type": "Airport", "object_type": "Country", "support": "Saranac Lake, New York, part of Harrietstown, New York, United States, is served by Adirondack Regional Airport.", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_66", "input text": "Saranac Lake is part of Harrietstown New York and has an airport called Adirondack Regional airport.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The Atlantic City International Airport is operated by the Port Authority of New York and New Jersey which serves the region of New Jersey and is based in New York.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Atlantic City International Airport\", \"operatingOrganisation\", \"Port Authority of New York and New Jersey\"], [\"Port Authority of New York and New Jersey\", \"regionServed\", \"New Jersey\"], [\"Port Authority of New York and New Jersey\", \"headquarter\", \"New York\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Saranac Lake is part of Harrietstown New York and has an airport called Adirondack Regional airport.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Saranac Lake\", \"isPartOf\", \"Harrietstown\"],\n      \"subject_type\": \"Place\",\n      \"object_type\": \"City\",\n      \"support\": \"Saranac Lake is part of Harrietstown New York\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Saranac Lake\", \"cityServed\", \"Saranac Lake\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Saranac Lake has an airport called Adirondack Regional airport\",\n      \"confidence\": 0.8\n    },\n    {\n      \"triple\": [\"Adirondack Regional airport\", \"city\", \"Saranac Lake\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Saranac Lake has an airport called Adirondack Regional airport\",\n      \"confidence\": 0.8\n    },\n    {\n      \"triple\": [\"Adirondack Regional airport\", \"iataCode\", \"not_mentioned_in_text\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"string\",\n      \"support\": \"not mentioned in the text\",\n      \"confidence\": 0.0\n    },\n    {\n      \"triple\": [\"Adirondack Regional airport\", \"icaoLocationIdentifier\", \"not_mentioned_in_text\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"string\",\n      \"support\": \"not mentioned in the text\",\n      \"confidence\": 0.0\n    },\n    {\n      \"triple\": [\"Adirondack Regional airport\", \"areaCode\", \"not_mentioned_in_text\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"string\",\n      \"support\": \"not mentioned in the text\",\n      \"confidence\": 0.0\n    },\n    {\n      \"triple\": [\"Adirondack Regional airport\", \"postalCode\", \"not_mentioned_in_text\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"string\",\n      \"support\": \"not mentioned in the text\",\n      \"confidence\": 0.0\n    },\n    {\n      \"triple\": [\"Adirondack Regional airport\", \"elevationAboveTheSeaLevel\", \"not_mentioned_in_text\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"not mentioned in the text\",\n      \"confidence\": 0.0\n    },\n    {\n      \"triple\": [\"Adirondack Regional airport\", \"elevationAboveTheSeaLevelInMetres\", \"not_mentioned_in_text\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"not mentioned in the text\",\n      \"confidence\": 0.0\n    },\n    {\n      \"triple\": [\"Adirondack Regional airport\", \"county\", \"not_mentioned_in_text\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"County\",\n      \"support\": \"not mentioned in the text\",\n      \"confidence\": 0.0\n    },\n    {\n      \"triple\": [\"Adirondack Regional airport\", \"division\", \"not_mentioned_in_text\"],", "json": null}}
{"id": "ont_3_airport_test_67", "input text": "Adirondack Regional Airport serves the city of Saranac Lake which like Harrietstown and Essex County is part of new York.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The Atlantic City International Airport is operated by the Port Authority of New York and New Jersey which serves the region of New Jersey and is based in New York.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Atlantic City International Airport\", \"operatingOrganisation\", \"Port Authority of New York and New Jersey\"], [\"Port Authority of New York and New Jersey\", \"regionServed\", \"New Jersey\"], [\"Port Authority of New York and New Jersey\", \"headquarter\", \"New York\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Adirondack Regional Airport serves the city of Saranac Lake which like Harrietstown and Essex County is part of new York.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Adirondack Regional Airport\", \"cityServed\", \"Saranac Lake\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Adirondack Regional Airport serves the city of Saranac Lake\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Saranac Lake\", \"partOf\", \"New York\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"Country\",\n      \"support\": \"Saranac Lake is part of New York\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Saranac Lake\", \"county\", \"Essex County\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"County\",\n      \"support\": \"Saranac Lake is part of Essex County\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Saranac Lake\", \"partOf\", \"Harrietstown\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"City\",\n      \"support\": \"Saranac Lake is part of Harrietstown\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Adirondack Regional Airport", "cityServed", "Saranac Lake"], "subject_type": "Airport", "object_type": "City", "support": "Adirondack Regional Airport serves the city of Saranac Lake", "confidence": 1.0}, {"triple": ["Saranac Lake", "partOf", "New York"], "subject_type": "City", "object_type": "Country", "support": "Saranac Lake is part of New York", "confidence": 1.0}, {"triple": ["Saranac Lake", "county", "Essex County"], "subject_type": "City", "object_type": "County", "support": "Saranac Lake is part of Essex County", "confidence": 1.0}, {"triple": ["Saranac Lake", "partOf", "Harrietstown"], "subject_type": "City", "object_type": "City", "support": "Saranac Lake is part of Harrietstown", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_68", "input text": "Adirondack Regional Airport is located in Saranac Lake Harrietstown, New York, United States.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The Atlantic City International Airport is operated by the Port Authority of New York and New Jersey which serves the region of New Jersey and is based in New York.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Atlantic City International Airport\", \"operatingOrganisation\", \"Port Authority of New York and New Jersey\"], [\"Port Authority of New York and New Jersey\", \"regionServed\", \"New Jersey\"], [\"Port Authority of New York and New Jersey\", \"headquarter\", \"New York\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Adirondack Regional Airport is located in Saranac Lake Harrietstown, New York, United States.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Adirondack Regional Airport\", \"location\", \"Saranac Lake Harrietstown\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Adirondack Regional Airport is located in Saranac Lake Harrietstown\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Adirondack Regional Airport\", \"country\", \"United States\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Country\",\n      \"support\": \"Adirondack Regional Airport, United States\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Adirondack Regional Airport", "location", "Saranac Lake Harrietstown"], "subject_type": "Airport", "object_type": "Place", "support": "Adirondack Regional Airport is located in Saranac Lake Harrietstown", "confidence": 1.0}, {"triple": ["Adirondack Regional Airport", "country", "United States"], "subject_type": "Airport", "object_type": "Country", "support": "Adirondack Regional Airport, United States", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_69", "input text": "Adirondack Regional Airport serves the city of Saranac Lake which is part of Essex County, New York, in the United States.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The Atlantic City International Airport is operated by the Port Authority of New York and New Jersey which serves the region of New Jersey and is based in New York.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Atlantic City International Airport\", \"operatingOrganisation\", \"Port Authority of New York and New Jersey\"], [\"Port Authority of New York and New Jersey\", \"regionServed\", \"New Jersey\"], [\"Port Authority of New York and New Jersey\", \"headquarter\", \"New York\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Adirondack Regional Airport serves the city of Saranac Lake which is part of Essex County, New York, in the United States.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Adirondack Regional Airport\", \"cityServed\", \"Saranac Lake\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Adirondack Regional Airport serves the city of Saranac Lake\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Saranac Lake\", \"partOf\", \"Essex County\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"County\",\n      \"support\": \"Saranac Lake which is part of Essex County\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Saranac Lake\", \"location\", \"New York\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"Place\",\n      \"support\": \"Saranac Lake, in the United States\",\n      \"confidence\": 0.8\n    },\n    {\n      \"triple\": [\"Adirondack Regional Airport\", \"county\", \"Essex County\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"County\",\n      \"support\": \"Saranac Lake which is part of Essex County, New York\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Adirondack Regional Airport", "cityServed", "Saranac Lake"], "subject_type": "Airport", "object_type": "City", "support": "Adirondack Regional Airport serves the city of Saranac Lake", "confidence": 1.0}, {"triple": ["Saranac Lake", "partOf", "Essex County"], "subject_type": "City", "object_type": "County", "support": "Saranac Lake which is part of Essex County", "confidence": 1.0}, {"triple": ["Saranac Lake", "location", "New York"], "subject_type": "City", "object_type": "Place", "support": "Saranac Lake, in the United States", "confidence": 0.8}, {"triple": ["Adirondack Regional Airport", "county", "Essex County"], "subject_type": "Airport", "object_type": "County", "support": "Saranac Lake which is part of Essex County, New York", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_70", "input text": "Abilene Regional Airport serves the city of Abilene which is part of Taylor County, Texas, in the United States.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Andrews County Airport is located in Texas (whose indigenes are called Texans), United States.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Andrews County Airport\", \"location\", \"Texas\"], [\"Texas\", \"demonym\", \"Texan\"], [\"Texas\", \"country\", \"United States\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Abilene Regional Airport serves the city of Abilene which is part of Taylor County, Texas, in the United States.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Abilene Regional Airport\", \"cityServed\", \"Abilene\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Abilene Regional Airport serves the city of Abilene\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Abilene\", \"partOf\", \"Taylor County\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"County\",\n      \"support\": \"which is part of Taylor County\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Taylor County\", \"location\", \"Texas\"],\n      \"subject_type\": \"County\",\n      \"object_type\": \"Place\",\n      \"support\": \"Taylor County, Texas\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Texas\", \"country\", \"United States\"],\n      \"subject_type\": \"Country\",\n      \"object_type\": \"Country\",\n      \"support\": \"in the United States.\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Abilene Regional Airport", "cityServed", "Abilene"], "subject_type": "Airport", "object_type": "City", "support": "Abilene Regional Airport serves the city of Abilene", "confidence": 1.0}, {"triple": ["Abilene", "partOf", "Taylor County"], "subject_type": "City", "object_type": "County", "support": "which is part of Taylor County", "confidence": 1.0}, {"triple": ["Taylor County", "location", "Texas"], "subject_type": "County", "object_type": "Place", "support": "Taylor County, Texas", "confidence": 1.0}, {"triple": ["Texas", "country", "United States"], "subject_type": "Country", "object_type": "Country", "support": "in the United States.", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_71", "input text": "Adirondack Regional Airport has a runway length of 1219.0 and serves the cities of Saranac Lake and Lake Placid, New York.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Atlantic City International Airport is operated by the Port Authority of New York and New Jersey. Its runway name is 4/22 and the length is 1873.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Atlantic City International Airport\", \"runwayLength\", \"1873.0\"], [\"Atlantic City International Airport\", \"operatingOrganisation\", \"Port Authority of New York and New Jersey\"], [\"Atlantic City International Airport\", \"runwayName\", \"4/22\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Adirondack Regional Airport has a runway length of 1219.0 and serves the cities of Saranac Lake and Lake Placid, New York.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Adirondack Regional Airport\", \"runwayLength\", \"1219.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"has a runway length of 1219.0\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Adirondack Regional Airport\", \"cityServed\", \"Saranac Lake, New York\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"serves the cities of Saranac Lake and Lake Placid, New York\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Adirondack Regional Airport\", \"cityServed\", \"Lake Placid, New York\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"serves the cities of Saranac Lake and Lake Placid, New York\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Adirondack Regional Airport", "runwayLength", "1219.0"], "subject_type": "Airport", "object_type": "number", "support": "has a runway length of 1219.0", "confidence": 1.0}, {"triple": ["Adirondack Regional Airport", "cityServed", "Saranac Lake, New York"], "subject_type": "Airport", "object_type": "City", "support": "serves the cities of Saranac Lake and Lake Placid, New York", "confidence": 1.0}, {"triple": ["Adirondack Regional Airport", "cityServed", "Lake Placid, New York"], "subject_type": "Airport", "object_type": "City", "support": "serves the cities of Saranac Lake and Lake Placid, New York", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_72", "input text": "The Indian Air Force in India, operates Agra Airport which uses VIAG as its ICAO location identifier.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Bedford Aerodrome's International Civil Aviation Organization (ICAO) identifier is EGBF and has a runway called 08/26.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Bedford Aerodrome\", \"icaoLocationIdentifier\", \"EGBF\"], [\"Bedford Aerodrome\", \"runwayName\", \"08/26\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The Indian Air Force in India, operates Agra Airport which uses VIAG as its ICAO location identifier.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"The Indian Air Force\", \"operator\", \"Agra Airport\"],\n      \"subject_type\": \"Organisation\",\n      \"object_type\": \"Airport\",\n      \"support\": \"The Indian Air Force operates Agra Airport\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Agra Airport\", \"icaoLocationIdentifier\", \"VIAG\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"string\",\n      \"support\": \"Agra Airport uses VIAG as its ICAO location identifier\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["The Indian Air Force", "operator", "Agra Airport"], "subject_type": "Organisation", "object_type": "Airport", "support": "The Indian Air Force operates Agra Airport", "confidence": 1.0}, {"triple": ["Agra Airport", "icaoLocationIdentifier", "VIAG"], "subject_type": "Airport", "object_type": "string", "support": "Agra Airport uses VIAG as its ICAO location identifier", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_73", "input text": "The 1st runway at Alderney Airport is made from Poaceae and has a length of 733.0. Alderney Airport serves the city of Alderney.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The 18L/36R runway of the Allama Iqbal International airport is located in Punjab Pakistan and has a length of 33310.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Allama Iqbal International Airport\", \"runwayLength\", \"3310.0\"], [\"Allama Iqbal International Airport\", \"location\", \"Punjab, Pakistan\"], [\"Allama Iqbal International Airport\", \"runwayName\", \"18L/36R\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The 1st runway at Alderney Airport is made from Poaceae and has a length of 733.0. Alderney Airport serves the city of Alderney.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alderney Airport\", \"runwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The 1st runway at Alderney Airport is made from Poaceae\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alderney Airport\", \"runwayLength\", \"733.0\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"Alderney Airport has a length of 733.0\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alderney Airport\", \"serves\", \"Alderney\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"Alderney Airport serves the city of Alderney\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alderney Airport", "runwaySurfaceType", "Poaceae"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "The 1st runway at Alderney Airport is made from Poaceae", "confidence": 1.0}, {"triple": ["Alderney Airport", "runwayLength", "733.0"], "subject_type": "Airport", "object_type": "number", "support": "Alderney Airport has a length of 733.0", "confidence": 1.0}, {"triple": ["Alderney Airport", "serves", "Alderney"], "subject_type": "Airport", "object_type": "City", "support": "Alderney Airport serves the city of Alderney", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_74", "input text": "Located in Wilson Township, Alpena County, Michigan, Alpena County Regional Airport has an elevation of 210 metres above sea level and a runway length of 1,533 metres.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Appleton International Airport located in Greenville, Wisconsin, has an elevation of 280 meters above sea level as well as a runway length of 2,439.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Appleton International Airport\", \"location\", \"Greenville, Wisconsin\"], [\"Appleton International Airport\", \"runwayLength\", \"2439.0\"], [\"Appleton International Airport\", \"elevationAboveTheSeaLevel\", \"280\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Located in Wilson Township, Alpena County, Michigan, Alpena County Regional Airport has an elevation of 210 metres above sea level and a runway length of 1,533 metres.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"location\", \"Wilson Township, Alpena County, Michigan\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Located in Wilson Township, Alpena County, Michigan\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"elevationAboveTheSeaLevel\", \"210\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"has an elevation of 210 metres above sea level\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"runwayLength\", \"1533\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"a runway length of 1,533 metres\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Alpena County Regional Airport\", \"county\", \"Alpena County\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"County\",\n      \"support\": \"in Alpena County\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Alpena County Regional Airport", "location", "Wilson Township, Alpena County, Michigan"], "subject_type": "Airport", "object_type": "Place", "support": "Located in Wilson Township, Alpena County, Michigan", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "elevationAboveTheSeaLevel", "210"], "subject_type": "Airport", "object_type": "number", "support": "has an elevation of 210 metres above sea level", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "runwayLength", "1533"], "subject_type": "Airport", "object_type": "number", "support": "a runway length of 1,533 metres", "confidence": 1.0}, {"triple": ["Alpena County Regional Airport", "county", "Alpena County"], "subject_type": "Airport", "object_type": "County", "support": "in Alpena County", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_75", "input text": "Angola International airport is located in Icolo e Bengo Angola, it has a runway length of 4000ft.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Adolfo Suárez Madrid Barajas Airport is found in Alcobendas and has the runway name of 14L/32R with a length of 4100.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Adolfo Suárez Madrid–Barajas Airport\", \"location\", \"Alcobendas\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayLength\", \"4100.0\"], [\"Adolfo Suárez Madrid–Barajas Airport\", \"runwayName\", \"14L/32R\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Angola International airport is located in Icolo e Bengo Angola, it has a runway length of 4000ft.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Angola International airport\", \"location\", \"Icolo e Bengo Angola\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Angola International airport is located in Icolo e Bengo Angola\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Angola International airport\", \"runwayLength\", \"4000ft\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"number\",\n      \"support\": \"it has a runway length of 4000ft\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Angola International airport", "location", "Icolo e Bengo Angola"], "subject_type": "Airport", "object_type": "Place", "support": "Angola International airport is located in Icolo e Bengo Angola", "confidence": 1.0}, {"triple": ["Angola International airport", "runwayLength", "4000ft"], "subject_type": "Airport", "object_type": "number", "support": "it has a runway length of 4000ft", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_76", "input text": "Angola International Airport is located at Ícolo e Bengo in Angola and the runway is named \"south runway\".", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Amsterdam is served by the Schiphol airport which is -3.3528 metres above sea level. The runway length is 3800.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Amsterdam Airport Schiphol\", \"cityServed\", \"Amsterdam\"], [\"Amsterdam Airport Schiphol\", \"runwayLength\", \"3800.0\"], [\"Amsterdam Airport Schiphol\", \"elevationAboveTheSeaLevel\", \"-3.3528\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Angola International Airport is located at Ícolo e Bengo in Angola and the runway is named \\\"south runway\\\".\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Angola International Airport\", \"location\", \"Ícolo e Bengo\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Place\",\n      \"support\": \"Angola International Airport is located at Ícolo e Bengo in Angola\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Angola International Airport\", \"runwayName\", \"south runway\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Runway\",\n      \"support\": \"the runway is named \\\"south runway\\\"\",\n      \"confidence\": 1.0\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Angola International Airport", "location", "Ícolo e Bengo"], "subject_type": "Airport", "object_type": "Place", "support": "Angola International Airport is located at Ícolo e Bengo in Angola", "confidence": 1.0}, {"triple": ["Angola International Airport", "runwayName", "south runway"], "subject_type": "Airport", "object_type": "Runway", "support": "the runway is named \"south runway\"", "confidence": 1.0}]}}}
{"id": "ont_3_airport_test_77", "input text": "The 3rd runway at Ardmore Airport (New Zealand) is made of Poaceae which is of the order Poales and belongs to the division of flowering plants.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The 18L/36R runway of the Allama Iqbal International airport is located in Punjab Pakistan and has a length of 33310.0.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Allama Iqbal International Airport\", \"runwayLength\", \"3310.0\"], [\"Allama Iqbal International Airport\", \"location\", \"Punjab, Pakistan\"], [\"Allama Iqbal International Airport\", \"runwayName\", \"18L/36R\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The 3rd runway at Ardmore Airport (New Zealand) is made of Poaceae which is of the order Poales and belongs to the division of flowering plants.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Ardmore Airport (New Zealand)\", \"runwaySurfaceType\", \"Poaceae\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"The 3rd runway at Ardmore Airport (New Zealand) is made of Poaceae\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Ardmore Airport (New Zealand)\", \"order\", \"Poales\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Division\",\n      \"support\": \"which is of the order Poales\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Ardmore Airport (New Zealand)", "runwaySurfaceType", "Poaceae"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "The 3rd runway at Ardmore Airport (New Zealand) is made of Poaceae", "confidence": 1.0}, {"triple": ["Ardmore Airport (New Zealand)", "order", "Poales"], "subject_type": "Airport", "object_type": "Division", "support": "which is of the order Poales", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_78", "input text": "The Athens International Airport serves the city of Athens, in Greece where Alexis Tsipras is the leader.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"Antwerp International Airport serves the city of Antwerp in Belgium where the leader is Philippe of Belgium.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Belgium\", \"leader\", \"Philippe of Belgium\"], [\"Antwerp International Airport\", \"cityServed\", \"Antwerp\"], [\"Antwerp\", \"country\", \"Belgium\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"The Athens International Airport serves the city of Athens, in Greece where Alexis Tsipras is the leader.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Athens International Airport\", \"cityServed\", \"Athens\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"City\",\n      \"support\": \"The Athens International Airport serves the city of Athens\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Athens\", \"country\", \"Greece\"],\n      \"subject_type\": \"City\",\n      \"object_type\": \"Country\",\n      \"support\": \"in Greece\",\n      \"confidence\": 1.0\n    },\n    {\n      \"triple\": [\"Athens International Airport\", \"leader\", \"Alexis Tsipras\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Person\",\n      \"support\": \"where Alexis Tsipras is the leader.\",\n      \"confidence\": 0.8\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Athens International Airport", "cityServed", "Athens"], "subject_type": "Airport", "object_type": "City", "support": "The Athens International Airport serves the city of Athens", "confidence": 1.0}, {"triple": ["Athens", "country", "Greece"], "subject_type": "City", "object_type": "Country", "support": "in Greece", "confidence": 1.0}, {"triple": ["Athens International Airport", "leader", "Alexis Tsipras"], "subject_type": "Airport", "object_type": "Person", "support": "where Alexis Tsipras is the leader.", "confidence": 0.8}]}}}
{"id": "ont_3_airport_test_79", "input text": "Poaceae is in the class Monocotyledon and the order of Commelinids. It is also the surface type of the second runway of Ardmore Airport, New Zealand.", "prompts": {"system_prompt": "You are an open IE extractor operating under a fixed ontology. From the text, propose triples [subject, relation, object] that satisfy the ontology’s domain→range. For every triple, cite exact supporting span(s) and give a 0–1 confidence. Output JSON only.", "user_prompt": "Task: Extract up to k triples that are directly supported by the text. You may paraphrase, but you must quote the evidence substrings.\n\n    Requirements\n    - Extract triples [subject, relation, object] that are explicitly supported by the text.\n    - For any triple that instantiates an ontology relation (i.e., its relation label appears in the ontology),\n      enforce domain→range consistency: the subject_type must match the relation’s domain concept, and\n      the object_type must match the relation’s range concept.\n    - You may also output factual triples that do NOT correspond to any ontology relation; in that case,\n      choose the most appropriate subject_type and object_type concept labels from the ontology, but do not discard the triple.\n    - Return JSON only, with this schema\n        {\n          \"triples\": [\n            {\n              \"triple\": [\"subject\",\"relation\",\"object\"],\n              \"subject_type\": \"Concept\",\n              \"object_type\": \"Concept\",\n              \"support\": \"exact quote from text\",\n              \"confidence\": 0.0\n            }\n          ]\n        }\n    - The confidence must be a real value between 0 and 1, estimated by how clearly the text supports the triple,\n      and how well subject_type and object_type match the ontology types.\n\n\n\nOne-shot EXAMPLE (for guidance; do not copy the text):\nExample sentence:\n\"The Bedford Aerodrome runway name is 08/26, it is 1095 long and the surface is made of concrete, it is also 83.2104 meters above sea level. The ICAO location identifier for the aerodrome is EGBF.\"\n\nExample triples (bare triples just to show what facts should emerge):\n[[\"Bedford Aerodrome\", \"runwayLength\", \"1095.0\"], [\"Bedford Aerodrome\", \"icaoLocationIdentifier\", \"EGBF\"], [\"Bedford Aerodrome\", \"elevationAboveTheSeaLevel\", \"83.2104\"], [\"Bedford Aerodrome\", \"runwayName\", \"08/26\"], [\"Bedford Aerodrome\", \"runwaySurfaceType\", \"Concrete\"]]\n\nNOTE:\n- The example triples above are simplified bare triples.\n- YOUR OUTPUT MUST follow the full schema described below\n  (with subject_type, object_type, support, and confidence in [0,1]).\n- Do not copy the example text; extract from the actual Text section only.\n\n    Text\n    \"Poaceae is in the class Monocotyledon and the order of Commelinids. It is also the surface type of the second runway of Ardmore Airport, New Zealand.\"\n\n    Ontology concepts\n    Airport, Aircraft, RunwaySurfaceType, Runway, Terminal, Airline, Organisation, Person, County, City, Country, Division, Demonym, Place, Battle, Language, Party, Class, Date, Year\n\n    Ontology relations (domain → range)\n    - aircraftFighter(Airport,Aircraft)\n- aircraftHelicopter(Airport,Aircraft)\n- transportAircraft(Airport,Aircraft)\n- hubAirport(Airport,Airport)\n- isPartOf(Airport,Airport)\n- runway(Airport,Runway)\n- runwayName(Airport,string)\n- runwayLength(Airport,number)\n- runwaySurfaceType(Airport,RunwaySurfaceType)\n- 1stRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 2ndRunwaySurfaceType(Airport,RunwaySurfaceType)\n- 3rdRunwaySurfaceType(Airport,RunwaySurfaceType)\n- terminal(Airport,Terminal)\n- iataCode(Airport,string)\n- icaoLocationIdentifier(Airport,string)\n- areaCode(Airport,string)\n- postalCode(Airport,string)\n- elevationAboveTheSeaLevel(Airport,number)\n- elevationAboveTheSeaLevelInMetres(Airport,number)\n- city(Airport,City)\n- cityServed(Airport,City)\n- largestCity(Airport,City)\n- regionServed(Airport,Place)\n- location(Airport,Place)\n- county(Airport,County)\n- ceremonialCounty(Airport,County)\n- division(Airport,Division)\n- country(Airport,Country)\n- capital(Airport,City)\n- headquarter(Airport,City)\n- officialLanguage(Airport,Language)\n- language(Airport,Language)\n- demonym(Airport,Demonym)\n- owner(Airport,Organisation)\n- operator(Airport,Organisation)\n- operatingOrganisation(Airport,Organisation)\n- airlineHub(Airport,Airline)\n- airlineServed(Airport,Airline)\n- leader(Airport,Person)\n- leaderTitle(Airport,string)\n- leaderParty(Airport,Party)\n- class(Airport,Class)\n- battle(Airport,Battle)\n- order(Airport,number)\n- areaTotal(Airport,number)\n- passengerCount(Airport,number)\n- aircraftMovements(Airport,number)\n- cargoTonnage(Airport,number)\n- numberOfRunways(Airport,number)\n- numberOfTerminals(Airport,number)\n- foundingYear(Airport,Year)\n- foundedBy(Airport,Person)\n- establishedDate(Airport,Date)\n- openingDate(Airport,Date)\n- constructionDate(Airport,Date)\n- expansionDate(Airport,Date)\n- closureDate(Airport,Date)\n- renovationDate(Airport,Date)\n- awardDate(Airport,Date)\n- timezone(Airport,string)\n- utcOffset(Airport,number)\n- website(Airport,string)\n- motto(Airport,string)\n\n    Constraints\n    - Extract ALL clearly stated factual triples in the text (not just those that match ontology relations).\n    - Do not discard a triple solely because it does not match any ontology relation; instead,\n      assign the best-fitting subject_type and object_type concepts you can infer from the ontology.\n    - For triples whose relation label appears in the ontology, respect the domain and range for subject_type and object_type.\n    - Always extract any explicit date, time, or year mentioned in the text as part of a factual triple when relevant.\n    - Resolve pronouns to the nearest valid antecedent if needed to form a correct triple.\n    - Do not invent entities that are not mentioned in the text.\n    - Output MUST be valid JSON and nothing else."}, "response": {"LLM_output": "{\n  \"triples\": [\n    {\n      \"triple\": [\"Poaceae\", \"runwaySurfaceType\", \"Commelinids\"],\n      \"subject_type\": \"Plant\",\n      \"object_type\": \"Class\",\n      \"support\": \"It is also the surface type of the second runway of Ardmore Airport, New Zealand.\",\n      \"confidence\": 0.5\n    },\n    {\n      \"triple\": [\"Ardmore Airport, New Zealand\", \"2ndRunwaySurfaceType\", \"Commelinids\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"Class\",\n      \"support\": \"It is also the surface type of the second runway of Ardmore Airport, New Zealand.\",\n      \"confidence\": 0.5\n    },\n    {\n      \"triple\": [\"Ardmore Airport, New Zealand\", \"runwaySurfaceType\", \"Commelinids (2nd runway)\"],\n      \"subject_type\": \"Airport\",\n      \"object_type\": \"RunwaySurfaceType\",\n      \"support\": \"It is also the surface type of the second runway of Ardmore Airport, New Zealand.\",\n      \"confidence\": 0.5\n    }\n  ]\n}", "json": {"triples": [{"triple": ["Poaceae", "runwaySurfaceType", "Commelinids"], "subject_type": "Plant", "object_type": "Class", "support": "It is also the surface type of the second runway of Ardmore Airport, New Zealand.", "confidence": 0.5}, {"triple": ["Ardmore Airport, New Zealand", "2ndRunwaySurfaceType", "Commelinids"], "subject_type": "Airport", "object_type": "Class", "support": "It is also the surface type of the second runway of Ardmore Airport, New Zealand.", "confidence": 0.5}, {"triple": ["Ardmore Airport, New Zealand", "runwaySurfaceType", "Commelinids (2nd runway)"], "subject_type": "Airport", "object_type": "RunwaySurfaceType", "support": "It is also the surface type of the second runway of Ardmore Airport, New Zealand.", "confidence": 0.5}]}}}
