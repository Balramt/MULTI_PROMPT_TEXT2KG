# MULTI_PROMPT_TEXT2KG

This repository contains the official implementation of our research framework for **Ontology-Aware Knowledge Graph Construction from Unstructured Text using Large Language Models (LLMs)**.

The system combines multiple prompting strategies with a hierarchical evaluator to improve extraction accuracy while mitigating hallucinations. It is designed and evaluated on the **Text2KGBench** benchmark.

---

# ğŸš€ Overview

Knowledge Graph (KG) construction from natural language is challenging due to:

- Incomplete supervision  
- Ontology constraints  
- Hallucinated entities and relations  
- Inconsistent triple formatting  

To address these issues, we propose a **multi-prompt ensemble framework** consisting of:

- ğŸ” **Structured Multi-Step Reasoning (ToT-based)**
- ğŸ“š **Ontology-Constrained OpenIE Prompt**
- âš¡ **General Ontology-Aware Extraction Prompt**
- ğŸ§  **Hierarchical Evaluator (Rules Aâ€“C)**

The evaluator filters candidate triples using cross-prompt agreement, explicit evidence scoring, and textual similarity measures to reduce hallucinations and enforce schema compliance.

---

# ğŸ“‚ Data Directory

The `data/` directory contains all datasets, ontologies, training data, and evaluation inputs required to reproduce the experiments.

## 1ï¸âƒ£ Input Text  
ğŸ”— https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/input_text  

Contains the raw input sentences for both **DBpediaâ€“WebNLG** and **Wikidataâ€“TekGen** datasets used during inference and evaluation.

---

## 2ï¸âƒ£ Ground Truth  
ğŸ”— https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/ground_truth  

Gold standard SPO triples for evaluation. These are used to compute **precision, recall, and F1-score**.

---

## 3ï¸âƒ£ Few-Shot Examples  
ğŸ”— https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/fewshots_example  

Example triples used inside prompts to guide the model during extraction (few-shot prompting).

---

## 4ï¸âƒ£ Ontology Files  
ğŸ”— https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/ontology/old_ontology  

Domain-specific ontology schemas containing:

- Concept sets  
- Relation definitions  
- Domainâ€“range constraints  

These are injected into prompts to enforce ontology-aware extraction.

---

## 5ï¸âƒ£ Training Data  
ğŸ”— https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/train_data  

Contains the combined and enriched training data used for fine-tuning the **LLaMA-3** model.

---

# ğŸ§  src/ â€“ Main Source Directory  

ğŸ”— https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/src  

The `src/` directory contains the complete implementation of:

- Synthetic data generation  
- Model fine-tuning  
- Multi-prompt triple extraction  
- Evaluator logic  
- Performance and hallucination evaluation  

Below is a breakdown of each component.

---

## ğŸ”¹ 1ï¸âƒ£ Synthetic Data Generation  

ğŸ”— https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/blob/main/src/Synthetic_train_data_generation_7B.py  

Generates additional ontology-aligned triples for **Wikidataâ€“TekGen** training data using a larger LLM.  
The script preserves seed triples and filters outputs based on ontology constraints to reduce noise.

---

## ğŸ”¹ 2ï¸âƒ£ LLaMA-3 Fine-Tuning  

ğŸ”— https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/blob/main/src/Llama_finetuned.py  

Performs supervised fine-tuning (SFT) of **LLaMA-3-8B-Instruct** using LoRA/QLoRA.  
The model learns structured JSON SPO output and ontology-aware relation naming.

---

# ğŸ” Multi-Prompt Triple Extraction Modules

## 1ï¸âƒ£ Structured Multi-Step Reasoning (ToT-Based Extractor)

ğŸ”— https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/blob/main/src/Llama_finetuned.py  

Implements a Tree-of-Thoughts (ToT) style extraction using depth-first search, state scoring, and pruning under ontology constraints.

---

## 2ï¸âƒ£ Ontology-Constrained OpenIE Prompt

ğŸ”— https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/blob/main/src/multi_prompt_extractor/Open_IE_prompt.py  

Single-pass ontology-aware extraction enforcing domainâ€“range constraints, semantic types, and textual evidence spans.

---

## 3ï¸âƒ£ General Ontology-Aware Extraction Prompt

ğŸ”— https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/blob/main/src/multi_prompt_extractor/general_extraction_prompt.py  

Lightweight SPO extraction with minimal structural constraints.  
Provides high recall and complementary coverage to stricter prompts.

---

# ğŸ§  Evaluator Module

ğŸ”— https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/blob/main/src/evaluator.py  

Implements hierarchical verification using:

- **Rule A â€“ Cross-Prompt Consensus**
- **Rule B â€“ Evidence-Based Validation**
- **Rule C â€“ Similarity-Based Filtering**

The evaluator merges and filters triples to reduce hallucinations and enforce schema compliance.

---

# ğŸ“Š Evaluation Scripts

ğŸ”— https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/blob/main/src/metrics_evaluation.py  

Computes:

- Precision  
- Recall  
- F1-score  
- Ontology Conformance (**OC â†‘**)  
- Subject Hallucination (**SH â†“**)  
- Relation Hallucination (**RH â†“**)  
- Object Hallucination (**OH â†“**)  

All reported metrics are calculated **after evaluator filtering**.
