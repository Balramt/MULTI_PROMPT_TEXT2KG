# MULTI_PROMPT_TEXT2KG

This repository contains the official implementation of our research framework for **Ontology-Aware Knowledge Graph Construction from Unstructured Text using Large Language Models (LLMs)**.

The system combines multiple prompting strategies with a hierarchical evaluator to improve extraction accuracy while mitigating hallucinations. It is designed and evaluated on the **Text2KGBench** benchmark.

---

# ğŸš€ Overview

Knowledge Graph (KG) construction from natural language is challenging due to:

- Incomplete supervision  
- Ontology constraints  
- Hallucinated entities and relations  
- Inconsistent triple formatting  

To address these issues, we propose a **multi-prompt ensemble framework** consisting of:

- ğŸ” **Structured Multi-Step Reasoning (ToT-based)**
- ğŸ“š **Ontology-Constrained OpenIE Prompt**
- âš¡ **General Ontology-Aware Extraction Prompt**
- ğŸ§  **Hierarchical Evaluator (Rules Aâ€“C)**

The evaluator filters candidate triples using cross-prompt agreement, explicit evidence scoring, and textual similarity measures to reduce hallucinations and enforce schema compliance.

---

# ğŸ“‚ Data Directory

# Input data

### ğŸ“‚ [`input_text`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/input_text)
Contains raw input sentences for both **DBpediaâ€“WebNLG** and **Wikidataâ€“TekGen** used during inference and evaluation.

1. [**DBpedia**](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/input_text/dbpedia)

2. [**Wikidata**](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/input_text/wikidata)

---

### ğŸ“‚ [`ground_truth`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/ground_truth)
Gold standard SPO triples used to compute **Precision, Recall, and F1-score**.

1. [**DBpedia**](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/ground_truth/dbpedia)

2. [**Wikidata**](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/ground_truth/wikidata)

---

### ğŸ“‚ [`fewshots_example`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/fewshots_example)
Few-shot examples injected into prompts to guide ontology-aligned triple extraction.

1. [**DBpedia**](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/fewshots_example/dbpedia)

2. [**Wikidata**](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/fewshots_example/wikidata)

---

### ğŸ“‚ [`ontology`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/ontology/old_ontology)
Domain-specific ontology schemas including:

- Concept definitions  
- Relation signatures  
- Domainâ€“range constraints  

These are directly injected into prompts to enforce schema compliance.

1. [**DBpedia Ontologies**](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/ontology/old_ontology/dbpedia)

2. [**Wikidata Ontologies**](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/input/ontology/old_ontology/wikidata)

---

### ğŸ“‚ [`train_data`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/train_data)
Combined and enriched training dataset used for **LLaMA-3 fine-tuning**.

1. [**DBpedia Training Data**](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/train_data/dbpedia)

2. **Wikidata Training Data (Synthetic Enrichment Pipeline)**  

   - [**Input Wikidata Train Data** ](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/train_data/wikidata/synthetic_train_data/wikidata_input_train)

   - [**Generated & Filtered Output Train Data Used for Fine-Tuning**](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/train_data/wikidata/synthetic_train_data/wikidata_output_train)

   The Wikidata dataset is synthetically enriched to compensate for incomplete distant supervision.  
   The filtered output data is directly used during LLaMA-3 supervised fine-tuning.

# ğŸ“¤ Output Data

This section contains all generated outputs from the multi-prompt extraction pipeline, evaluator filtering stage, and final evaluation metrics.

---

## ğŸ” Multi-Prompt Extraction Outputs

Each prompting strategy generates an independent candidate triple set before evaluator filtering.

### ğŸ”¹ [`TOT_dfs`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/output/multi_step_prompts/TOT_dfs)
Structured **Tree-of-Thoughts (ToT)-based depth-first search extraction** outputs.  
Includes intermediate reasoning states and final candidate triples generated under ontology constraints.

---

### ğŸ”¹ [`Open_IE_prompt`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/output/multi_step_prompts/Open_IE_prompt)
Outputs from the **Ontology-Constrained Open Information Extraction** prompt.  
Single-pass extraction enforcing domainâ€“range constraints, semantic typing, and evidence spans.

---

### ğŸ”¹ [`general_extraction_prompt`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/output/multi_step_prompts/general_extraction_prompt)
Outputs from the **General Ontology-Aware Extraction Prompt**.  
Lightweight high-recall SPO extraction with minimal structural constraints.

---

## ğŸ§  Evaluator-Filtered Outputs

### ğŸ”¹ [`evaluator_filtered_output`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/output/evaluator_filtered_output)

Final merged and filtered triple sets after applying:

- Rule A â€“ Cross-Prompt Consensus  
- Rule B â€“ Evidence-Based Validation  
- Rule C â€“ Similarity-Based Filtering  

All reported experimental results are computed using these filtered outputs.

---

## ğŸ“Š Evaluation Results

### ğŸ”¹ [`metrics_evaluation`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/output/metrics_evaluation)

Contains performance and hallucination metrics computed after evaluator filtering.

### ğŸ“ Dataset-wise Results

1. [**DBpediaâ€“WebNLG**](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/output/metrics_evaluation/dbpedia)

2. [**Wikidataâ€“TekGen**](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/data/output/metrics_evaluation/wikidata)

---

### ğŸ“ˆ Reported Metrics

- Precision (P)  
- Recall (R)  
- F1-score (F1)  
- Ontology Conformance (OC â†‘)  
- Subject Hallucination (SH â†“)  
- Relation Hallucination (RH â†“)  
- Object Hallucination (OH â†“)  

All metrics are computed on the **evaluator-filtered triple sets**.



# ğŸ§  Source Code (`src/`)

### ğŸ“‚ [`src`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/tree/main/src)
Contains the full implementation of:

- Synthetic data generation  
- Model fine-tuning  
- Multi-prompt extraction  
- Evaluator logic  
- Evaluation metrics  

---

## ğŸ”¹ Data Preparation & Training

### ğŸ“‚ [`Synthetic_train_data_generation_7B.py`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/blob/main/src/Synthetic_train_data_generation_7B.py)
Generates ontology-filtered synthetic triples for **Wikidataâ€“TekGen** using a larger LLM.  
Preserves seed triples and removes out-of-schema relations to improve training quality.

---

### ğŸ“‚ [`Llama_finetuned.py`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/blob/main/src/Llama_finetuned.py)
Performs supervised fine-tuning (SFT) of **LLaMA-3-8B-Instruct** using LoRA/QLoRA.  
Trains the model to generate structured JSON SPO triples with ontology-aware relation naming.

---

# ğŸ” Multi-Prompt Extraction Modules

### ğŸ“‚ [`ToT-Based Structured Extractor`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/blob/main/src/Llama_finetuned.py)
Implements Tree-of-Thoughts style extraction with depth-first search, state scoring, and pruning under ontology constraints.

---

### ğŸ“‚ [`Open_IE_prompt.py`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/blob/main/src/multi_prompt_extractor/Open_IE_prompt.py)
Single-pass ontology-constrained OpenIE extraction enforcing domainâ€“range rules, semantic typing, and evidence spans.

---

### ğŸ“‚ [`general_extraction_prompt.py`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/blob/main/src/multi_prompt_extractor/general_extraction_prompt.py)
Lightweight ontology-aware SPO extraction with minimal structural constraints, providing high recall and complementary coverage.

---

# ğŸ§  Evaluator

### ğŸ“‚ [`evaluator.py`](https://github.com/Balramt/MULTI_PROMPT_TEXT2KG/blob/main/src/evaluator.py)
Implements hierarchical triple verification:

- **Rule A â€“ Cross-Prompt Consensus**
- **Rule B â€“ Evidence-Based Validation**
- **Rule C â€“ Similarity-Based Filtering**

Merges and filters candidate triples to reduce hallucinations and ensure ontology consistency.

---
